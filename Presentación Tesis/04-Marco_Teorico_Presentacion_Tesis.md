# 04-Marco_Teorico_Presentacion_Tesis.md

## Speech para la sección de Marco Teórico

---

### Slide 1: Redes Neuronales Convolucionales (CNN)

"Las redes neuronales convolucionales, o CNN, son la base del análisis de imágenes médicas. Permiten extraer características espaciales relevantes y se utilizan ampliamente en tareas de clasificación, segmentación y detección. En pantalla pueden ver un esquema referencial de una red neuronal."

---

### Slide 2: ResNet50: Arquitectura Residual

"ResNet50 es una arquitectura profunda con 50 capas y conexiones residuales. Estas conexiones facilitan el entrenamiento de redes muy profundas, evitando el problema del desvanecimiento del gradiente. En esta tesis, ResNet50 se emplea como backbone para la extracción de características en imágenes de rayos X."

---

### Slide 3: Redes Neuronales Recurrentes (RNN)

"Las redes neuronales recurrentes, o RNN, procesan secuencias de datos y mantienen información temporal, lo que es útil para tareas donde el contexto previo es importante. Existen variantes como LSTM y GRU que mejoran la capacidad de memoria de estas redes. Aquí se muestra el grafo computacional de una RNN desenrollada."

---

### Slide 4: Mecanismos de Atención y Transformers

"Los mecanismos de atención permiten a los modelos enfocarse en partes relevantes de la entrada. Los Transformers revolucionaron el procesamiento de secuencias al permitir el procesamiento paralelo y el uso de atención múltiple, conocido como Multi-Head Attention. El Vision Transformer, o ViT, aplica estos conceptos al análisis de imágenes."

---

### Slide 5: Resumen del Marco Teórico

"En resumen, se combinan arquitecturas convolucionales como ResNet50 y modelos basados en atención como los Transformers para la detección de patologías pulmonares. El uso de Transfer Learning y Fine-Tuning permite adaptar modelos preentrenados a imágenes médicas, mejorando la precisión y la interpretabilidad en el diagnóstico asistido por inteligencia artificial."
