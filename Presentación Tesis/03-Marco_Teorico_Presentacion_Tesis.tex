% 04-Marco_Teorico_Presentacion_Tesis.tex
% Diapositivas de la sección Marco Teórico

\section{Marco Teórico}

\begin{frame}
\frametitle{Redes Neuronales Convolucionales (CNN)}
\begin{itemize}
    \item Las CNN son la base del análisis de imágenes médicas.
    \item Permiten extraer características espaciales relevantes de las imágenes.
    \item Se utilizan ampliamente en tareas de clasificación, segmentación y detección.
\end{itemize}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{images/convolutional_network.png}
    \caption{Esquema de referencia de una red neuronal convolucional.}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Estructura de una red convolucional}
\begin{itemize}
    \item \textbf{Capa de Convolución}: Extrae características locales (bordes, texturas, patrones) mediante filtros (kernels).
    \item \textbf{Capa de Activación} (ReLU, LeakyReLU, etc.): Introduce no linealidad y elimina valores negativos.
    \item \textbf{Capa de Pooling}: Reduce la dimensionalidad conservando la información más relevante.
    \item \textbf{Capas Fully Connected} (Dense): Al final de la red, se aplanan los feature maps y se conectan a neuronas tradicionales para clasificación/regresión.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Aplicaciones de una red convolucional}
\begin{itemize}
    \item \textbf{Clasificación de imágenes}: ResNet, VGG
    \item \textbf{Detección de objetos}: YOLO, Faster R-CNN
    \item \textbf{Segmentación semántica}: U-Net
    \item \textbf{Procesamiento de lenguaje natural}: CNNs para texto
\end{itemize}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/cnn_applications.png}
    \caption{Aplicaciones de una red neuronal convolucional.}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{ResNet50: Arquitectura Residual}
\begin{itemize}
    \item ResNet50 es una arquitectura profunda con 50 capas y conexiones residuales.
    \item Facilita el entrenamiento de redes muy profundas evitando el problema del desvanecimiento del gradiente.
    \item En esta tesis, ResNet50 se emplea como backbone para la extracción de características en imágenes de rayos X.
\end{itemize}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\textwidth]{images/resnet50_architecture.png}
    \caption{Arquitectura base de un modelo ResNet.}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{¿Por qué ResNet50 para esta tesis?}
\begin{itemize}
    \item \textbf{Buen rendimiento}: Probado en tareas de clasificación de imágenes médicas
    \item \textbf{Arquitectura establecida}: Ampliamente validada en la comunidad científica
    \item \textbf{Balance óptimo}: Entre profundidad y eficiencia computacional
    \item \textbf{Transfer learning efectivo}: Desde ImageNet a imágenes médicas
    \item \textbf{Capacidad de captura}: Características complejas en imágenes de rayos X
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Redes Neuronales Recurrentes (RNN)}
\begin{itemize}
    \item Las RNN procesan secuencias de datos, manteniendo información temporal.
    \item Son útiles para tareas donde el contexto previo es importante.
    \item Existen variantes como LSTM y GRU que mejoran la capacidad de memoria.
\end{itemize}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/rnn.png}
    \caption{Grafo computacional de una RNN desenrollada.}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Mecanismos de Atención y Transformers}
\begin{itemize}
    \item Los Transformers revolucionaron el procesamiento de secuencias al permitir el procesamiento paralelo y el uso de atención múltiple (Multi-Head Attention).
    \item Los mecanismos de atención permiten al modelo enfocarse en partes relevantes de la entrada.
    \item Vision Transformer (ViT) aplica estos conceptos a imágenes.
\end{itemize}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.42\textwidth]{images/attention.png}
    \caption{Ilustración del mecanismo de atención obtenida de la publicación "All you need is Attention".}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Mecanismos de Atención y Transformers}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\textwidth]{images/vit.png}
    \caption{Ilustración del modelo ViT obtenida de la publicación "An Image is worth 16X16 words".}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Mecanismos de Atención y Transformers}
\begin{table}[h!]
    \centering
    \fontsize{7}{8}\selectfont
    \begin{tabular}{|p{2.5cm}|p{3cm}|p{3cm}|}
        \hline
        \textbf{Característica} & \textbf{Transformers (con atención)} & \textbf{RNNs / BiRNNs} \\
        \hline
        Paralelización & Totalmente paralelizable durante el entrenamiento & Procesamiento secuencial, difícil de paralelizar \\
        \hline
        Dependencias a largo plazo & Captura relaciones entre tokens distantes fácilmente & Difícil de mantener contexto a largo plazo \\
        \hline
        Velocidad de entrenamiento & Más rápido gracias a la paralelización & Más lento por la naturaleza secuencial \\
        \hline
        Escalabilidad & Escala bien con grandes cantidades de datos y capas & Escalabilidad limitada por problemas de gradiente \\
        \hline
        Multi-head attention & Permite aprender múltiples representaciones en paralelo & No tiene un mecanismo equivalente \\
        \hline
        Representación contextual rica & Cada token se representa en función de todos los demás & Representación más local y secuencial \\
        \hline
    \end{tabular}
    \caption{Comparación entre Transformers y RNNs/BiRNNs en tareas de modelado de secuencias}
    \label{tab:comparacion_transformers_rnns}
\end{table}
\end{frame}

\begin{frame}
\frametitle{Resumen del Marco Teórico}
\begin{itemize}
    \item Se presentan dos modelos de arquitecturas para el procesamiento y detección de patologías pulmonares
        \begin{itemize}
            \item Convolucionales (ResNet50). Extrayendo características de las imágenes, a través de la convolución de filtros.
            \item Modelos basados en atención (ViT). Procesando imágenes como secuencias de datos, manteniendo información temporal.
        \end{itemize}
\end{itemize}
\end{frame}

% \begin{frame}
% \frametitle{Resumen del Marco Teórico}
% \begin{table}[h!]
%     \centering
%     \fontsize{8}{9}\selectfont
%     \begin{tabular}{|p{2.5cm}|p{3cm}|p{3cm}|}
%         \hline
%         \textbf{Aspecto} & \textbf{CNNs} & \textbf{Vision Transformers (ViT)} \\
%         \hline
%         Extracción de características & Local y jerárquica & Global desde el inicio \\
%         \hline
%         Interpretación espacial & Implícita por la estructura convolucional & Necesita codificación posicional \\
%         \hline
%         Campo receptivo (Receptive field) & Aumenta con la profundidad & Global desde la primera capa \\
%         \hline
%         Transferencia de conocimiento & Muy efectiva con preentrenamiento & Requiere mucho preentrenamiento para funcionar bien \\
%         \hline
%     \end{tabular}
%     \caption{Comparación entre redes convolucionales (CNNs) y Vision Transformers (ViT)}
%     \label{tab:comparacion_cnns_vit}
% \end{table}
% \end{frame}
