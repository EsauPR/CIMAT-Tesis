% This happens to be the bibliography from the thesis of Cole Meisenhelder, '15

% To actually cite articles in your document you will use the \cite{}; the first item in each of the entries below is the identifier used to call these articles, i.e. \cite{Meisenhelder}

% Citation information can be obtained from NASA ADS. After you click on the abstract, select Export Citation, and use the BibTex format.

%% Saved with string encoding Unicode (UTF-8)

@article{Rumelhart,
	author={Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	title={Learning representations by back-propagating errors},
	journal={Nature},
	year={1986},
	month={Oct},
	day={01},
	volume={323},
	number={6088},
	pages={533-536},
	abstract={We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	issn={1476-4687},
	doi={10.1038/323533a0},
	url={https://doi.org/10.1038/323533a0}
}

@article{Vaswani,
	author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Schuster,
	author={Schuster, M. and Paliwal, K.K.},
	journal={IEEE Transactions on Signal Processing},
	title={Bidirectional recurrent neural networks},
	year={1997},
	volume={45},
	number={11},
	pages={2673-2681},
	doi={10.1109/78.650093}
}

@article{LSTM,
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@inbook{VanishinGradient,
	author={Kolen, John F. and Kremer, Stefan C.},
	booktitle={A Field Guide to Dynamical Recurrent Networks},
	title={Gradient Flow in Recurrent Nets: The Difficulty of Learning LongTerm Dependencies},
	year={2001},
	volume={},
	number={},
	pages={237-243},
	doi={10.1109/9780470544037.ch14}
}

@article{VanishinGradient2,
	author={Bengio, Y. and Simard, P. and Frasconi, P.},
	journal={IEEE Transactions on Neural Networks},
	title={Learning long-term dependencies with gradient descent is difficult},
	year={1994},
	volume={5},
	number={2},
	pages={157-166},
	doi={10.1109/72.279181}
}


@Book{GoodBengCour16,
	Title = {Deep Learning},
	Author = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
	Publisher = {MIT Press},
	Year = {2017},
	Address = {Cambridge, MA},
	Note = {\url{http://www.deeplearningbook.org}}
}

@article{GRU1,
	author    = {KyungHyun Cho and
				Bart van Merrienboer and
				Dzmitry Bahdanau and
				Yoshua Bengio},
	title     = {On the Properties of Neural Machine Translation: Encoder-Decoder Approaches},
	journal   = {CoRR},
	volume    = {abs/1409.1259},
	year      = {2014},
	url       = {http://arxiv.org/abs/1409.1259},
	archivePrefix = {arXiv},
	eprint    = {1409.1259},
	timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ChoMBB14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GRU2,
	author    = {Junyoung Chung and
				{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
				KyungHyun Cho and
				Yoshua Bengio},
	title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
				Modeling},
	journal   = {CoRR},
	volume    = {abs/1412.3555},
	year      = {2014},
	url       = {http://arxiv.org/abs/1412.3555},
	archivePrefix = {arXiv},
	eprint    = {1412.3555},
	timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ChungGCB14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bahdanau2016neural,
	title={Neural Machine Translation by Jointly Learning to Align and Translate},
	author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
	year={2016},
	eprint={1409.0473},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}


@article{DBLP:journals/corr/GravesWD14,
	Author    = {Alex Graves and
				Greg Wayne and
				Ivo Danihelka},
	title     = {Neural Turing Machines},
	journal   = {CoRR},
	volume    = {abs/1410.5401},
	year      = {2014},
	url       = {http://arxiv.org/abs/1410.5401},
	archivePrefix = {arXiv},
	eprint    = {1410.5401},
	timestamp = {Mon, 13 Aug 2018 16:46:28 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/GravesWD14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/LuongPM15,
	author    = {Minh{-}Thang Luong and
				Hieu Pham and
				Christopher D. Manning},
	title     = {Effective Approaches to Attention-based Neural Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1508.04025},
	year      = {2015},
	url       = {http://arxiv.org/abs/1508.04025},
	archivePrefix = {arXiv},
	eprint    = {1508.04025},
	timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/LuongPM15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/VaswaniSPUJGKP17,
	author    = {Ashish Vaswani and
				Noam Shazeer and
				Niki Parmar and
				Jakob Uszkoreit and
				Llion Jones and
				Aidan N. Gomez and
				Lukasz Kaiser and
				Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{weng2018attention,
	title   = "Attention? Attention!",
	author  = "Weng, Lilian",
	journal = "lilianweng.github.io/lil-log",
	year    = "2018",
	url     = "http://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html"
}

@article{DBLP:journals/corr/ChoMGBSB14,
	author    = {Kyunghyun Cho and
				Bart van Merrienboer and
				{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
				Fethi Bougares and
				Holger Schwenk and
				Yoshua Bengio},
	title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
				Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1406.1078},
	year      = {2014},
	url       = {http://arxiv.org/abs/1406.1078},
	archivePrefix = {arXiv},
	eprint    = {1406.1078},
	timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ChoMGBSB14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/SordoniBB16,
	author    = {Alessandro Sordoni and
				Philip Bachman and
				Yoshua Bengio},
	title     = {Iterative Alternating Neural Attention for Machine Reading},
	journal   = {CoRR},
	volume    = {abs/1606.02245},
	year      = {2016},
	url       = {http://arxiv.org/abs/1606.02245},
	archivePrefix = {arXiv},
	eprint    = {1606.02245},
	timestamp = {Mon, 22 Jul 2019 13:00:16 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SordoniBB16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1709-00893,
	author    = {Dehong Ma and
				Sujian Li and
				Xiaodong Zhang and
				Houfeng Wang},
	title     = {Interactive Attention Networks for Aspect-Level Sentiment Classification},
	journal   = {CoRR},
	volume    = {abs/1709.00893},
	year      = {2017},
	url       = {http://arxiv.org/abs/1709.00893},
	archivePrefix = {arXiv},
	eprint    = {1709.00893},
	timestamp = {Mon, 23 Nov 2020 08:36:40 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00893.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2009-14794,
	author    = {Krzysztof Choromanski and
				Valerii Likhosherstov and
				David Dohan and
				Xingyou Song and
				Andreea Gane and
				Tam{\'{a}}s Sarl{\'{o}}s and
				Peter Hawkins and
				Jared Davis and
				Afroz Mohiuddin and
				Lukasz Kaiser and
				David Belanger and
				Lucy J. Colwell and
				Adrian Weller},
	title     = {Rethinking Attention with Performers},
	journal   = {CoRR},
	volume    = {abs/2009.14794},
	year      = {2020},
	url       = {https://arxiv.org/abs/2009.14794},
	archivePrefix = {arXiv},
	eprint    = {2009.14794},
	timestamp = {Wed, 23 Jun 2021 10:58:18 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2009-14794.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1810-10126,
	author    = {Yang Li and
				Lukasz Kaiser and
				Samy Bengio and
				Si Si},
	title     = {Area Attention},
	journal   = {CoRR},
	volume    = {abs/1810.10126},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.10126},
	archivePrefix = {arXiv},
	eprint    = {1810.10126},
	timestamp = {Thu, 26 Sep 2019 08:29:12 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1810-10126.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Pavlopoulos,
	author = {Pavlopoulos, John and Malakasiotis, Prodromos and Androutsopoulos, Ion},
	year = {2017},
	month = {01},
	pages = {1125-1135},
	title = {Deeper Attention to Abusive User Content Moderation},
	doi = {10.18653/v1/D17-1117}
}

@InProceedings{pmlr-v28-pascanu13,
	title = {On the difficulty of training recurrent neural networks},
	author = {Razvan Pascanu and Tomas Mikolov and Yoshua Bengio},
	booktitle = {Proceedings of the 30th International Conference on Machine Learning},
	pages = {1310--1318},
	year = {2013},
	editor = {Sanjoy Dasgupta and David McAllester},
	volume = {28(3)},
	series = {Proceedings of Machine Learning Research},
	address = {Atlanta, Georgia, USA},
	month = {17--19 Jun}
}

@article{DBLP:journals/corr/abs-1904-02874,
	author    = {Sneha Chaudhari and
				Gungor Polatkan and
				Rohan Ramanath and
				Varun Mithal},
	title     = {An Attentive Survey of Attention Models},
	journal   = {CoRR},
	volume    = {abs/1904.02874},
	year      = {2019},
	url       = {http://arxiv.org/abs/1904.02874},
	archivePrefix = {arXiv},
	eprint    = {1904.02874},
	timestamp = {Wed, 24 Apr 2019 12:21:25 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1904-02874.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MartinsA16,
	author    = {Andr{\'{e}} F. T. Martins and
				Ram{\'{o}}n Fernandez Astudillo},
	title     = {From Softmax to Sparsemax: {A} Sparse Model of Attention and Multi-Label
				Classification},
	journal   = {CoRR},
	volume    = {abs/1602.02068},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.02068},
	archivePrefix = {arXiv},
	eprint    = {1602.02068},
	timestamp = {Mon, 26 Oct 2020 15:47:01 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/MartinsA16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2006-07214,
	author    = {Andr{\'{e}} F. T. Martins and
				Marcos V. Treviso and
				Ant{\'{o}}nio Farinhas and
				Vlad Niculae and
				M{\'{a}}rio A. T. Figueiredo and
				Pedro M. Q. Aguiar},
	title     = {Sparse and Continuous Attention Mechanisms},
	journal   = {CoRR},
	volume    = {abs/2006.07214},
	year      = {2020},
	url       = {https://arxiv.org/abs/2006.07214},
	archivePrefix = {arXiv},
	eprint    = {2006.07214},
	timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07214.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NEURIPS2019_16fc18d7,
	author = {Tay, Yi and Luu, Anh Tuan and Zhang, Aston and Wang, Shuohang and Hui, Siu Cheung},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Compositional De-Attention Networks},
	url = {https://proceedings.neurips.cc/paper/2019/file/16fc18d787294ad5171100e33d05d4e2-Paper.pdf},
	volume = {32},
	year = {2019}
}

@InProceedings{yang2016hierarchical,
	author = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
	title = {Hierarchical Attention Networks for Document Classification},
	booktitle = {NAACL 2016},
	year = {2016},
	month = {June},
	abstract = {We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences.},
	url = {https://www.microsoft.com/en-us/research/publication/hierarchical-attention-networks-document-classification/},
	pages = {1480-1489},
	edition = {NAACL 2016},
}

@article{DBLP:journals/corr/XuBKCCSZB15,
  author    = {Kelvin Xu and
               Jimmy Ba and
               Ryan Kiros and
               Kyunghyun Cho and
               Aaron C. Courville and
               Ruslan Salakhutdinov and
               Richard S. Zemel and
               Yoshua Bengio},
  title     = {Show, Attend and Tell: Neural Image Caption Generation with Visual
               Attention},
  journal   = {CoRR},
  volume    = {abs/1502.03044},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.03044},
  archivePrefix = {arXiv},
  eprint    = {1502.03044},
  timestamp = {Mon, 13 Aug 2018 16:47:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/XuBKCCSZB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/GehringAGYD17,
  author    = {Jonas Gehring and
               Michael Auli and
               David Grangier and
               Denis Yarats and
               Yann N. Dauphin},
  title     = {Convolutional Sequence to Sequence Learning},
  journal   = {CoRR},
  volume    = {abs/1705.03122},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.03122},
  archivePrefix = {arXiv},
  eprint    = {1705.03122},
  timestamp = {Mon, 13 Aug 2018 16:48:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GehringAGYD17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1908-03265,
  author    = {Liyuan Liu and
               Haoming Jiang and
               Pengcheng He and
               Weizhu Chen and
               Xiaodong Liu and
               Jianfeng Gao and
               Jiawei Han},
  title     = {On the Variance of the Adaptive Learning Rate and Beyond},
  journal   = {CoRR},
  volume    = {abs/1908.03265},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.03265},
  archivePrefix = {arXiv},
  eprint    = {1908.03265},
  timestamp = {Mon, 19 Aug 2019 13:21:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-03265.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1910-04209,
  author    = {Jerry Ma and
               Denis Yarats},
  title     = {On the adequacy of untuned warmup for adaptive optimization},
  journal   = {CoRR},
  volume    = {abs/1910.04209},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.04209},
  archivePrefix = {arXiv},
  eprint    = {1910.04209},
  timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-04209.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1804-00247,
  author    = {Martin Popel and
               Ondrej Bojar},
  title     = {Training Tips for the Transformer Model},
  journal   = {CoRR},
  volume    = {abs/1804.00247},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.00247},
  archivePrefix = {arXiv},
  eprint    = {1804.00247},
  timestamp = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-00247.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v119-huang20f,
  title = 	 {Improving Transformer Optimization Through Better Initialization},
  author =       {Huang, Xiao Shi and Perez, Felipe and Ba, Jimmy and Volkovs, Maksims},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {4475--4483},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/huang20f/huang20f.pdf},
  url = 	 {https://proceedings.mlr.press/v119/huang20f.html},
  abstract = 	 {The Transformer architecture has achieved considerable success recently; the key component of the Transformer is the attention layer that enables the model to focus on important regions within an input sequence. Gradient optimization with attention layers can be notoriously difficult requiring tricks such as learning rate warmup to prevent divergence. As Transformer models are becoming larger and more expensive to train, recent research has focused on understanding and improving optimization in these architectures. In this work our contributions are two-fold: we first investigate and empirically validate the source of optimization problems in the encoder-decoder Transformer architecture; we then propose a new weight initialization scheme with theoretical justification, that enables training without warmup or layer normalization. Empirical results on public machine translation benchmarks show that our approach achieves leading accuracy, allowing to train deep Transformer models with 200 layers in both encoder and decoder (over 1000 attention/MLP blocks) without difficulty. Code for this work is available here:&nbsp;\url{https://github.com/layer6ai-labs/T-Fixup}.}
}

@article{DBLP:journals/corr/abs-1711-02132,
  author    = {Karim Ahmed and
               Nitish Shirish Keskar and
               Richard Socher},
  title     = {Weighted Transformer Network for Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1711.02132},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.02132},
  archivePrefix = {arXiv},
  eprint    = {1711.02132},
  timestamp = {Mon, 13 Aug 2018 16:48:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-02132.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2002-04745,
  author    = {Ruibin Xiong and
               Yunchang Yang and
               Di He and
               Kai Zheng and
               Shuxin Zheng and
               Chen Xing and
               Huishuai Zhang and
               Yanyan Lan and
               Liwei Wang and
               Tie{-}Yan Liu},
  title     = {On Layer Normalization in the Transformer Architecture},
  journal   = {CoRR},
  volume    = {abs/2002.04745},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.04745},
  archivePrefix = {arXiv},
  eprint    = {2002.04745},
  timestamp = {Sat, 23 Jan 2021 01:14:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-04745.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1804-09849,
  author    = {Mia Xu Chen and
               Orhan Firat and
               Ankur Bapna and
               Melvin Johnson and
               Wolfgang Macherey and
               George F. Foster and
               Llion Jones and
               Niki Parmar and
               Mike Schuster and
               Zhifeng Chen and
               Yonghui Wu and
               Macduff Hughes},
  title     = {The Best of Both Worlds: Combining Recent Advances in Neural Machine
               Translation},
  journal   = {CoRR},
  volume    = {abs/1804.09849},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.09849},
  archivePrefix = {arXiv},
  eprint    = {1804.09849},
  timestamp = {Fri, 20 Mar 2020 09:13:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-09849.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1802-05751,
  author    = {Niki Parmar and
               Ashish Vaswani and
               Jakob Uszkoreit and
               Lukasz Kaiser and
               Noam Shazeer and
               Alexander Ku},
  title     = {Image Transformer},
  journal   = {CoRR},
  volume    = {abs/1802.05751},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.05751},
  archivePrefix = {arXiv},
  eprint    = {1802.05751},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-05751.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1904-10509,
  author    = {Rewon Child and
               Scott Gray and
               Alec Radford and
               Ilya Sutskever},
  title     = {Generating Long Sequences with Sparse Transformers},
  journal   = {CoRR},
  volume    = {abs/1904.10509},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.10509},
  archivePrefix = {arXiv},
  eprint    = {1904.10509},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-10509.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1905-07799,
  author    = {Sainbayar Sukhbaatar and
               Edouard Grave and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Adaptive Attention Span in Transformers},
  journal   = {CoRR},
  volume    = {abs/1905.07799},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.07799},
  archivePrefix = {arXiv},
  eprint    = {1905.07799},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-07799.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1901-02860,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc V. Le and
               Ruslan Salakhutdinov},
  title     = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  journal   = {CoRR},
  volume    = {abs/1901.02860},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.02860},
  eprinttype = {arXiv},
  eprint    = {1901.02860},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-02860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-05150,
  author    = {Iz Beltagy and
               Matthew E. Peters and
               Arman Cohan},
  title     = {Longformer: The Long-Document Transformer},
  journal   = {CoRR},
  volume    = {abs/2004.05150},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.05150},
  eprinttype = {arXiv},
  eprint    = {2004.05150},
  timestamp = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-05150.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1906-11024,
  author    = {Tong Xiao and
               Yinqiao Li and
               Jingbo Zhu and
               Zhengtao Yu and
               Tongran Liu},
  title     = {Sharing Attention Weights for Fast Transformer},
  journal   = {CoRR},
  volume    = {abs/1906.11024},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.11024},
  eprinttype = {arXiv},
  eprint    = {1906.11024},
  timestamp = {Mon, 08 Jul 2019 16:13:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-11024.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2006-04768,
  author    = {Sinong Wang and
               Belinda Z. Li and
               Madian Khabsa and
               Han Fang and
               Hao Ma},
  title     = {Linformer: Self-Attention with Linear Complexity},
  journal   = {CoRR},
  volume    = {abs/2006.04768},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.04768},
  eprinttype = {arXiv},
  eprint    = {2006.04768},
  timestamp = {Fri, 12 Jun 2020 14:02:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-04768.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2001-04451,
  author    = {Nikita Kitaev and
               Lukasz Kaiser and
               Anselm Levskaya},
  title     = {Reformer: The Efficient Transformer},
  journal   = {CoRR},
  volume    = {abs/2001.04451},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.04451},
  eprinttype = {arXiv},
  eprint    = {2001.04451},
  timestamp = {Sat, 23 Jan 2021 01:20:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-04451.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2105-03824,
  author    = {James Lee{-}Thorp and
               Joshua Ainslie and
               Ilya Eckstein and
               Santiago Onta{\~{n}}{\'{o}}n},
  title     = {FNet: Mixing Tokens with Fourier Transforms},
  journal   = {CoRR},
  volume    = {abs/2105.03824},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.03824},
  eprinttype = {arXiv},
  eprint    = {2105.03824},
  timestamp = {Fri, 14 May 2021 12:13:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-03824.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2108-09084,
  author    = {Chuhan Wu and
               Fangzhao Wu and
               Tao Qi and
               Yongfeng Huang and
               Xing Xie},
  title     = {Fastformer: Additive Attention Can Be All You Need},
  journal   = {CoRR},
  volume    = {abs/2108.09084},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.09084},
  eprinttype = {arXiv},
  eprint    = {2108.09084},
  timestamp = {Thu, 02 Sep 2021 08:19:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-09084.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2103-02440,
  author    = {Sven Kreiss and
               Lorenzo Bertoni and
               Alexandre Alahi},
  title     = {OpenPifPaf: Composite Fields for Semantic Keypoint Detection and Spatio-Temporal
               Association},
  journal   = {CoRR},
  volume    = {abs/2103.02440},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.02440},
  eprinttype = {arXiv},
  eprint    = {2103.02440},
  timestamp = {Thu, 04 Mar 2021 17:00:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-02440.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2012-13392,
  author    = {Ce Zheng and
               Wenhan Wu and
               Taojiannan Yang and
               Sijie Zhu and
               Chen Chen and
               Ruixu Liu and
               Ju Shen and
               Nasser Kehtarnavaz and
               Mubarak Shah},
  title     = {Deep Learning-Based Human Pose Estimation: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2012.13392},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.13392},
  eprinttype = {arXiv},
  eprint    = {2012.13392},
  timestamp = {Tue, 05 Jan 2021 16:02:31 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-13392.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{MOESLUND2001231,
  title = {A Survey of Computer Vision-Based Human Motion Capture},
  journal = {Computer Vision and Image Understanding},
  volume = {81},
  number = {3},
  pages = {231-268},
  year = {2001},
  issn = {1077-3142},
  doi = {https://doi.org/10.1006/cviu.2000.0897},
  url = {https://www.sciencedirect.com/science/article/pii/S107731420090897X},
  author = {Thomas B. Moeslund and Erik Granum},
  abstract = {A comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented. The focus is on a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition. Each process is discussed and divided into subprocesses and/or categories of methods to provide a reference to describe and compare the more than 130 publications covered by the survey. References are included throughout the paper to exemplify important issues and their relations to the various methods. A number of general assumptions used in this research field are identified and the character of these assumptions indicates that the research field is still in an early stage of development. To evaluate the state of the art, the major application areas are identified and performances are analyzed in light of the methods presented in the survey. Finally, suggestions for future research directions are offered.}
}

@article{MOESLUND200690,
  title = {A survey of advances in vision-based human motion capture and analysis},
  journal = {Computer Vision and Image Understanding},
  volume = {104},
  number = {2},
  pages = {90-126},
  year = {2006},
  note = {Special Issue on Modeling People: Vision-based understanding of a person’s shape, appearance, movement and behaviour},
  issn = {1077-3142},
  doi = {https://doi.org/10.1016/j.cviu.2006.08.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1077314206001263},
  author = {Thomas B. Moeslund and Adrian Hilton and Volker Krüger},
  keywords = {Review, Human motion, Initialization, Tracking, Pose estimation, Recognition},
  abstract = {This survey reviews advances in human motion capture and analysis from 2000 to 2006, following a previous survey of papers up to 2000 [T.B. Moeslund, E. Granum, A survey of computer vision-based human motion capture, Computer Vision and Image Understanding, 81(3) (2001) 231–268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization, tracking, pose estimation, and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis, as well as discussing open problems for future research to achieve automatic visual analysis of human movement.}
}

@article{POPPE20074,
title = {Vision-based human motion analysis: An overview},
journal = {Computer Vision and Image Understanding},
volume = {108},
number = {1},
pages = {4-18},
year = {2007},
note = {Special Issue on Vision for Human-Computer Interaction},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2006.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S1077314206002293},
author = {Ronald Poppe},
keywords = {Human motion analysis, Pose estimation, Computer vision},
abstract = {Markerless vision-based human motion analysis has the potential to provide an inexpensive, non-obtrusive solution for the estimation of body poses. The significant research effort in this domain has been motivated by the fact that many application areas, including surveillance, Human–Computer Interaction and automatic annotation, will benefit from a robust solution. In this paper, we discuss the characteristics of human motion analysis. We divide the analysis into a modeling and an estimation phase. Modeling is the construction of the likelihood function, estimation is concerned with finding the most likely pose given the likelihood surface. We discuss model-free approaches separately. This taxonomy allows us to highlight trends in the domain and to point out limitations of the current state of the art.}
}

@ARTICLE{5191035,
  author={Ji, Xiaofei and Liu, Honghai},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  title={Advances in View-Invariant Human Motion Analysis: A Review},
  year={2010},
  volume={40},
  number={1},
  pages={13-24},
  doi={10.1109/TSMCC.2009.2027608}
}

@ARTICLE{6193117,
  author={Holte, Michael B. and Tran, Cuong and Trivedi, Mohan M. and Moeslund, Thomas B.},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  title={Human Pose Estimation and Activity Recognition From Multi-View Videos: Comparative Explorations of Recent Developments},
  year={2012},
  volume={6},
  number={5},
  pages={538-552},
  doi={10.1109/JSTSP.2012.2196975}
}

@article{LIU201510,
  title = {A survey of human pose estimation: The body parts parsing based methods},
  journal = {Journal of Visual Communication and Image Representation},
  volume = {32},
  pages = {10-19},
  year = {2015},
  issn = {1047-3203},
  doi = {https://doi.org/10.1016/j.jvcir.2015.06.013},
  url = {https://www.sciencedirect.com/science/article/pii/S1047320315001121},
  author = {Zhao Liu and Jianke Zhu and Jiajun Bu and Chun Chen},
  keywords = {Human pose estimation, Articulated object detection, Survey, Body parts parsing, Motion capture, Feature Extraction, Appearance models, Structure models},
  abstract = {Estimating human pose from videos and image sequences is not only an important computer vision problem, but also plays very critical role in many real-world applications. Main challenges for human pose estimation are variation of body poses, complicated background and depth ambiguities. To solve these problems, considerable research efforts have been devoted to the related fields. In this survey, we focus our attention on the recent advances in vision-based human pose estimation. We first present a general framework of human pose estimation, and then go through the latest technical progress on each stage. Finally, we discuss the limitations of the existing approaches and foresee the future directions to be explored.}
}

@Article{Gong2016,
  author={Gong, Wenjuan
  and Zhang, Xuena
  and Gonz{\`a}lez, Jordi
  and Sobral, Andrews
  and Bouwmans, Thierry
  and Tu, Changhe
  and Zahzah, El-Hadi},
  title={Human Pose Estimation from Monocular Images: A Comprehensive Survey},
  journal={Sensors (Basel, Switzerland)},
  year={2016},
  month={Nov},
  day={25},
  publisher={MDPI},
  volume={16},
  number={12},
  pages={1966},
  keywords={bottom-up methods; discriminative methods; generative methods; human body models; human pose estimation; top-down methods; Algorithms; Humans; Image Processing, Computer-Assisted; Pattern Recognition, Automated; Posture/*physiology},
  abstract={Human pose estimation refers to the estimation of the location of body parts and how they are connected in an image. Human pose estimation from monocular images has wide applications (e.g., image indexing). Several surveys on human pose estimation can be found in the literature, but they focus on a certain category; for example, model-based approaches or human motion analysis, etc. As far as we know, an overall review of this problem domain has yet to be provided. Furthermore, recent advancements based on deep learning have brought novel algorithms for this problem. In this paper, a comprehensive survey of human pose estimation from monocular images is carried out including milestone works and recent advancements. Based on one standard pipeline for the solution of computer vision problems, this survey splits the problem into several modules: feature extraction and description, human body models, and modeling methods. Problem modeling methods are approached based on two means of categorization in this survey. One way to categorize includes top-down and bottom-up methods, and another way includes generative and discriminative methods. Considering the fact that one direct application of human pose estimation is to provide initialization for automatic video surveillance, there are additional sections for motion-related methods in all modules: motion features, motion models, and motion-based methods. Finally, the paper also collects 26 publicly available data sets for validation and provides error measurement methods that are frequently used.},
  note={27898003[pmid]},
  note={PMC5190962[pmcid]},
  note={s16121966[PII]},
  issn={1424-8220},
  doi={10.3390/s16121966},
  url={https://pubmed.ncbi.nlm.nih.gov/27898003},
  url={https://doi.org/10.3390/s16121966},
  language={eng}
}

@article{SARAFIANOS20161,
  title = {3D Human pose estimation: A review of the literature and analysis of covariates},
  journal = {Computer Vision and Image Understanding},
  volume = {152},
  pages = {1-20},
  year = {2016},
  issn = {1077-3142},
  doi = {https://doi.org/10.1016/j.cviu.2016.09.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1077314216301369},
  author = {Nikolaos Sarafianos and Bogdan Boteanu and Bogdan Ionescu and Ioannis A. Kakadiaris},
  keywords = {3D Human pose estimation, Articulated tracking, Anthropometry, Human motion analysis},
  abstract = {Estimating the pose of a human in 3D given an image or a video has recently received significant attention from the scientific community. The main reasons for this trend are the ever increasing new range of applications (e.g., human-robot interaction, gaming, sports performance analysis) which are driven by current technological advances. Although recent approaches have dealt with several challenges and have reported remarkable results, 3D pose estimation remains a largely unsolved problem because real-life applications impose several challenges which are not fully addressed by existing methods. For example, estimating the 3D pose of multiple people in an outdoor environment remains a largely unsolved problem. In this paper, we review the recent advances in 3D human pose estimation from RGB images or image sequences. We propose a taxonomy of the approaches based on the input (e.g., single image or video, monocular or multi-view) and in each case we categorize the methods according to their key characteristics. To provide an overview of the current capabilities, we conducted an extensive experimental evaluation of state-of-the-art approaches in a synthetic dataset created specifically for this task, which along with its ground truth is made publicly available for research purposes. Finally, we provide an in-depth discussion of the insights obtained from reviewing the literature and the results of our experiments. Future directions and challenges are identified.}
}

@article{CHEN2020102897,
title = {Monocular human pose estimation: A survey of deep learning-based methods},
journal = {Computer Vision and Image Understanding},
volume = {192},
pages = {102897},
year = {2020},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2019.102897},
url = {https://www.sciencedirect.com/science/article/pii/S1077314219301778},
author = {Yucheng Chen and Yingli Tian and Mingyi He},
keywords = {Deep learning, Human pose estimation, Survey},
abstract = {Vision-based monocular human pose estimation, as one of the most fundamental and challenging problems in computer vision, aims to obtain posture of the human body from input images or video sequences. The recent developments of deep learning techniques have been brought significant progress and remarkable breakthroughs in the field of human pose estimation. This survey extensively reviews the recent deep learning-based 2D and 3D human pose estimation methods published since 2014. This paper summarizes the challenges, main frameworks, benchmark datasets, evaluation metrics, performance comparison, and discusses some promising future research directions.}
}

@ARTICLE{9144178,
  author={Munea, Tewodros Legesse and Jembre, Yalew Zelalem and Weldegebriel, Halefom Tekle and Chen, Longbiao and Huang, Chenxi and Yang, Chenhui},
  journal={IEEE Access},
  title={The Progress of Human Pose Estimation: A Survey and Taxonomy of Models Applied in 2D Human Pose Estimation},
  year={2020},
  volume={8},
  number={},
  pages={133330-133348},
  doi={10.1109/ACCESS.2020.3010248}
}

@article{DBLP:journals/corr/RenHG015,
  author    = {Shaoqing Ren and
               Kaiming He and
               Ross B. Girshick and
               Jian Sun},
  title     = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
               Networks},
  journal   = {CoRR},
  volume    = {abs/1506.01497},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.01497},
  eprinttype = {arXiv},
  eprint    = {1506.01497},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-10934,
  author    = {Alexey Bochkovskiy and
               Chien{-}Yao Wang and
               Hong{-}Yuan Mark Liao},
  title     = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  journal   = {CoRR},
  volume    = {abs/2004.10934},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.10934},
  eprinttype = {arXiv},
  eprint    = {2004.10934},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10934.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/RedmonDGF15,
  author    = {Joseph Redmon and
               Santosh Kumar Divvala and
               Ross B. Girshick and
               Ali Farhadi},
  title     = {You Only Look Once: Unified, Real-Time Object Detection},
  journal   = {CoRR},
  volume    = {abs/1506.02640},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02640},
  eprinttype = {arXiv},
  eprint    = {1506.02640},
  timestamp = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RedmonDGF15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.04861},
  eprinttype = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Thu, 27 May 2021 16:20:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HowardZCKWWAA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1801-04381,
  author    = {Mark Sandler and
               Andrew G. Howard and
               Menglong Zhu and
               Andrey Zhmoginov and
               Liang{-}Chieh Chen},
  title     = {Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification,
               Detection and Segmentation},
  journal   = {CoRR},
  volume    = {abs/1801.04381},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.04381},
  eprinttype = {arXiv},
  eprint    = {1801.04381},
  timestamp = {Tue, 12 Jan 2021 15:30:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1801-04381.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1711-06396,
  author    = {Yin Zhou and
               Oncel Tuzel},
  title     = {VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection},
  journal   = {CoRR},
  volume    = {abs/1711.06396},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.06396},
  eprinttype = {arXiv},
  eprint    = {1711.06396},
  timestamp = {Mon, 13 Aug 2018 16:46:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-06396.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{6165146,
  author={Tong, Jing and Zhou, Jin and Liu, Ligang and Pan, Zhigeng and Yan, Hao},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  title={Scanning 3D Full Human Bodies Using Kinects},
  year={2012},
  volume={18},
  number={4},
  pages={643-650},
  doi={10.1109/TVCG.2012.56}}

@INPROCEEDINGS{Izadi11kinectfusion:real-time,
    author = {Shahram Izadi and David Kim and Otmar Hilliges and David Molyneaux and Richard Newcombe and Pushmeet Kohli and Jamie Shotton and Steve Hodges and Dustin Freeman and Andrew Davison and Andrew Fitzgibbon},
    title = {Kinectfusion: real-time 3D reconstruction and interaction using a moving depth camera},
    booktitle = {In Proc. UIST},
    year = {2011},
    pages = {559--568}
}

@ARTICLE{6682899,
  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
  year={2014},
  volume={36},
  number={7},
  pages={1325-1339},
  doi={10.1109/TPAMI.2013.248}}

@article{articleMotion,
  author = {Roetenberg, Daniel and Luinge, Henk and Slycke, Per},
  year = {2009},
  month = {01},
  pages = {},
  title = {Xsens MVN: Full 6DOF human motion tracking using miniature inertial sensors},
  volume = {3},
  journal = {Xsens Motion Technol. BV Tech. Rep.}
}

@article{DBLP:journals/corr/abs-1907-00837,
  author    = {Dushyant Mehta and
               Oleksandr Sotnychenko and
               Franziska Mueller and
               Weipeng Xu and
               Mohamed Elgharib and
               Pascal Fua and
               Hans{-}Peter Seidel and
               Helge Rhodin and
               Gerard Pons{-}Moll and
               Christian Theobalt},
  title     = {XNect: Real-time Multi-person 3D Human Pose Estimation with a Single
               {RGB} Camera},
  journal   = {CoRR},
  volume    = {abs/1907.00837},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.00837},
  eprinttype = {arXiv},
  eprint    = {1907.00837},
  timestamp = {Tue, 24 Sep 2019 15:40:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-00837.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@Article{Felzenszwalb2005,
  author={Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  title={Pictorial Structures for Object Recognition},
  journal={International Journal of Computer Vision},
  year={2005},
  month={Jan},
  day={01},
  volume={61},
  number={1},
  pages={55-79},
  abstract={In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.},
  issn={1573-1405},
  doi={10.1023/B:VISI.0000042934.15159.49},
  url={https://doi.org/10.1023/B:VISI.0000042934.15159.49}
}

@INPROCEEDINGS{557241,
  author={Ju, S.X. and Black, M.J. and Yacoob, Y.},
  booktitle={Proceedings of the Second International Conference on Automatic Face and Gesture Recognition},
  title={Cardboard people: a parameterized model of articulated image motion},
  year={1996},
  volume={},
  number={},
  pages={38-44},
  doi={10.1109/AFGR.1996.557241}}

@article{COOTES199538,
  title = {Active Shape Models-Their Training and Application},
  journal = {Computer Vision and Image Understanding},
  volume = {61},
  number = {1},
  pages = {38-59},
  year = {1995},
  issn = {1077-3142},
  doi = {https://doi.org/10.1006/cviu.1995.1004},
  url = {https://www.sciencedirect.com/science/article/pii/S1077314285710041},
  author = {T.F. Cootes and C.J. Taylor and D.H. Cooper and J. Graham},
  abstract = {Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply model-based methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images.}
}

@INPROCEEDINGS{840661,
  author={Sidenbladh, H. and De la Torre, F. and Black, M.J.},
  booktitle={Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)},
  title={A framework for modeling the appearance of 3D articulated figures},
  year={2000},
  volume={},
  number={},
  pages={368-375},
  doi={10.1109/AFGR.2000.840661}}

@article{DBLP:journals/corr/MartinezHRL17,
  author    = {Julieta Martinez and
               Rayat Hossain and
               Javier Romero and
               James J. Little},
  title     = {A simple yet effective baseline for 3d human pose estimation},
  journal   = {CoRR},
  volume    = {abs/1705.03098},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.03098},
  eprinttype = {arXiv},
  eprint    = {1705.03098},
  timestamp = {Mon, 13 Aug 2018 16:46:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MartinezHRL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8954163,
  author={Pavllo, Dario and Feichtenhofer, Christoph and Grangier, David and Auli, Michael},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={3D Human Pose Estimation in Video With Temporal Convolutions and Semi-Supervised Training},
  year={2019},
  volume={},
  number={},
  pages={7745-7754},
  doi={10.1109/CVPR.2019.00794}}

@article{DBLP:journals/corr/abs-2002-10322,
  author    = {Tianlang Chen and
               Chen Fang and
               Xiaohui Shen and
               Yiheng Zhu and
               Zhili Chen and
               Jiebo Luo},
  title     = {Anatomy-aware 3D Human Pose Estimation in Videos},
  journal   = {CoRR},
  volume    = {abs/2002.10322},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.10322},
  eprinttype = {arXiv},
  eprint    = {2002.10322},
  timestamp = {Tue, 03 Mar 2020 14:32:13 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-10322.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1711-08585,
  author    = {Mir Rayat Imtiaz Hossain and
               James J. Little},
  title     = {Exploiting temporal information for 3D pose estimation},
  journal   = {CoRR},
  volume    = {abs/1711.08585},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.08585},
  eprinttype = {arXiv},
  eprint    = {1711.08585},
  timestamp = {Mon, 13 Aug 2018 16:46:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-08585.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1904-05547,
  author    = {Chen Li and
               Gim Hee Lee},
  title     = {Generating Multiple Hypotheses for 3D Human Pose Estimation with Mixture
               Density Network},
  journal   = {CoRR},
  volume    = {abs/1904.05547},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.05547},
  eprinttype = {arXiv},
  eprint    = {1904.05547},
  timestamp = {Thu, 25 Apr 2019 13:55:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-05547.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2009-00348,
  author    = {Adrian Llopart},
  title     = {LiftFormer: 3D Human Pose Estimation using attention models},
  journal   = {CoRR},
  volume    = {abs/2009.00348},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.00348},
  eprinttype = {arXiv},
  eprint    = {2009.00348},
  timestamp = {Wed, 16 Sep 2020 15:27:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-00348.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-11822,
  author    = {Yu Cheng and
               Bo Yang and
               Bo Wang and
               Robby T. Tan},
  title     = {3D Human Pose Estimation using Spatio-Temporal Networks with Explicit
               Occlusion Training},
  journal   = {CoRR},
  volume    = {abs/2004.11822},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.11822},
  eprinttype = {arXiv},
  eprint    = {2004.11822},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-11822.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1905-05754,
  author    = {Karim Iskakov and
               Egor Burkov and
               Victor S. Lempitsky and
               Yury Malkov},
  title     = {Learnable Triangulation of Human Pose},
  journal   = {CoRR},
  volume    = {abs/1905.05754},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05754},
  eprinttype = {arXiv},
  eprint    = {1905.05754},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05754.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1901-04111,
  author    = {Junting Dong and
               Wen Jiang and
               Qixing Huang and
               Hujun Bao and
               Xiaowei Zhou},
  title     = {Fast and Robust Multi-Person 3D Pose Estimation from Multiple Views},
  journal   = {CoRR},
  volume    = {abs/1901.04111},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.04111},
  eprinttype = {arXiv},
  eprint    = {1901.04111},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-04111.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-06239,
  author    = {Hanyue Tu and
               Chunyu Wang and
               Wenjun Zeng},
  title     = {End-to-End Estimation of Multi-Person 3D Poses from Multiple Cameras},
  journal   = {CoRR},
  volume    = {abs/2004.06239},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.06239},
  eprinttype = {arXiv},
  eprint    = {2004.06239},
  timestamp = {Tue, 21 Apr 2020 16:51:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-06239.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/NewellYD16,
  author    = {Alejandro Newell and
               Kaiyu Yang and
               Jia Deng},
  title     = {Stacked Hourglass Networks for Human Pose Estimation},
  journal   = {CoRR},
  volume    = {abs/1603.06937},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.06937},
  eprinttype = {arXiv},
  eprint    = {1603.06937},
  timestamp = {Mon, 01 Feb 2021 18:33:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/NewellYD16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/WeiRKS16,
  author    = {Shih{-}En Wei and
               Varun Ramakrishna and
               Takeo Kanade and
               Yaser Sheikh},
  title     = {Convolutional Pose Machines},
  journal   = {CoRR},
  volume    = {abs/1602.00134},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.00134},
  eprinttype = {arXiv},
  eprint    = {1602.00134},
  timestamp = {Mon, 13 Aug 2018 16:48:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WeiRKS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1804-06208,
  author    = {Bin Xiao and
               Haiping Wu and
               Yichen Wei},
  title     = {Simple Baselines for Human Pose Estimation and Tracking},
  journal   = {CoRR},
  volume    = {abs/1804.06208},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.06208},
  eprinttype = {arXiv},
  eprint    = {1804.06208},
  timestamp = {Mon, 13 Aug 2018 16:47:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-06208.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8578840,
  author={Chen, Yilun and Wang, Zhicheng and Peng, Yuxiang and Zhang, Zhiqiang and Yu, Gang and Sun, Jian},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title={Cascaded Pyramid Network for Multi-person Pose Estimation},
  year={2018},
  volume={},
  number={},
  pages={7103-7112},
  doi={10.1109/CVPR.2018.00742}}

@article{DBLP:journals/corr/InsafutdinovPAA16,
  author    = {Eldar Insafutdinov and
               Leonid Pishchulin and
               Bjoern Andres and
               Mykhaylo Andriluka and
               Bernt Schiele},
  title     = {DeeperCut: {A} Deeper, Stronger, and Faster Multi-Person Pose Estimation
               Model},
  journal   = {CoRR},
  volume    = {abs/1605.03170},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.03170},
  eprinttype = {arXiv},
  eprint    = {1605.03170},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/InsafutdinovPAA16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{8765346,
  author={Cao, Zhe and Hidalgo, Gines and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields},
  year={2021},
  volume={43},
  number={1},
  pages={172-186},
  doi={10.1109/TPAMI.2019.2929257}}

@article{DBLP:journals/corr/FangXL16,
  author    = {Haoshu Fang and
               Shuqin Xie and
               Cewu Lu},
  title     = {{RMPE:} Regional Multi-person Pose Estimation},
  journal   = {CoRR},
  volume    = {abs/1612.00137},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.00137},
  eprinttype = {arXiv},
  eprint    = {1612.00137},
  timestamp = {Mon, 13 Aug 2018 16:48:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FangXL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{andriluka14cvpr,
  author = {Mykhaylo Andriluka and Leonid Pishchulin and Peter Gehler and Schiele, Bernt},
  title = {2D Human Pose Estimation: New Benchmark and State of the Art Analysis},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2014},
  month = {June}
}

@article{DBLP:journals/corr/LinMBHPRDZ14,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  eprinttype = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Trumble:BMVC:2017,
  AUTHOR = "Trumble, Matt and Gilbert, Andrew and Malleson, Charles and  Hilton, Adrian and Collomosse, John",
  TITLE = "Total Capture: 3D Human Pose Estimation Fusing Video and Inertial Sensors",
  BOOKTITLE = "2017 British Machine Vision Conference (BMVC)",
  YEAR = "2017",
}

@article{DBLP:journals/corr/Varol0MMBLS17,
  author    = {G{\"{u}}l Varol and
               Javier Romero and
               Xavier Martin and
               Naureen Mahmood and
               Michael J. Black and
               Ivan Laptev and
               Cordelia Schmid},
  title     = {Learning from Synthetic Humans},
  journal   = {CoRR},
  volume    = {abs/1701.01370},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.01370},
  eprinttype = {arXiv},
  eprint    = {1701.01370},
  timestamp = {Mon, 13 Aug 2018 16:46:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Varol0MMBLS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fabbri2018learning,
   title     = {Learning to Detect and Track Visible and Occluded Body Joints in a Virtual World},
   author    = {Fabbri, Matteo and Lanzi, Fabio and Calderara, Simone and Palazzi, Andrea and
                Vezzani, Roberto and Cucchiara, Rita},
   booktitle = {European Conference on Computer Vision (ECCV)},
   year      = {2018}
 }

@INPROCEEDINGS{4587468,
  author={Ferrari, Vittorio and Marin-Jimenez, Manuel and Zisserman, Andrew},
  booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition},
  title={Progressive search space reduction for human pose estimation},
  year={2008},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/CVPR.2008.4587468}}

@INPROCEEDINGS{6619315,
  author={Sapp, Ben and Taskar, Ben},
  booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition},
  title={MODEC: Multimodal Decomposable Models for Human Pose Estimation},
  year={2013},
  volume={},
  number={},
  pages={3674-3681},
  doi={10.1109/CVPR.2013.471}}

  @article{DBLP:journals/corr/ToshevS13,
  author    = {Alexander Toshev and
               Christian Szegedy},
  title     = {DeepPose: Human Pose Estimation via Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1312.4659},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.4659},
  eprinttype = {arXiv},
  eprint    = {1312.4659},
  timestamp = {Mon, 13 Aug 2018 16:48:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ToshevS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{6380498,
  author={Yang, Yi and Ramanan, Deva},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Articulated Human Detection with Flexible Mixtures of Parts},
  year={2013},
  volume={35},
  number={12},
  pages={2878-2890},
  doi={10.1109/TPAMI.2012.261}}

@INPROCEEDINGS{6909866,
  author={Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and Schiele, Bernt},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
  title={2D Human Pose Estimation: New Benchmark and State of the Art Analysis},
  year={2014},
  volume={},
  number={},
  pages={3686-3693},
  doi={10.1109/CVPR.2014.471}}

@Article{Gower1975,
author={Gower, J. C.},
title={Generalized procrustes analysis},
journal={Psychometrika},
year={1975},
month={Mar},
day={01},
volume={40},
number={1},
pages={33-51},
abstract={SupposePi(i)(i = 1, 2, ...,m, j = 1, 2, ...,n) give the locations ofmn points inp-dimensional space. Collectively these may be regarded asm configurations, or scalings, each ofn points inp-dimensions. The problem is investigated of translating, rotating, reflecting and scaling them configurations to minimize the goodness-of-fit criterion $\Sigma$i=1m$\Sigma$i=1n$\Delta$2(Pj(i)Gi), whereGiis the centroid of them pointsPi(i)(i = 1, 2, ...,m). The rotated positions of each configuration may be regarded as individual analyses with the centroid configuration representing a consensus, and this relationship with individual scaling analysis is discussed. A computational technique is given, the results of which can be summarized in analysis of variance form. The special casem = 2 corresponds to Classical Procrustes analysis but the choice of criterion that fits each configuration to the common centroid configuration avoids difficulties that arise when one set is fitted to the other, regarded as fixed.},
issn={1860-0980},
doi={10.1007/BF02291478},
url={https://doi.org/10.1007/BF02291478}
}

@article{DBLP:journals/corr/MehtaRCSXT16,
  author    = {Dushyant Mehta and
               Helge Rhodin and
               Dan Casas and
               Oleksandr Sotnychenko and
               Weipeng Xu and
               Christian Theobalt},
  title     = {Monocular 3D Human Pose Estimation Using Transfer Learning and Improved
               {CNN} Supervision},
  journal   = {CoRR},
  volume    = {abs/1611.09813},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.09813},
  eprinttype = {arXiv},
  eprint    = {1611.09813},
  timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MehtaRCSXT16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% related methods

@article{long2016unsupervised,
  title={Unsupervised domain adaptation with residual transfer networks},
  author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
  journal={arXiv preprint arXiv:1602.04433},
  year={2016}
}


@inproceedings{kingma2015adam,
  title={Adam: A method for stochastic gradient descent},
  author={Kingma, Diederik P and Ba, Jimmy Lei},
  booktitle={ICLR: International Conference on Learning Representations},
  pages={1--15},
  year={2015}
}


@article{bressem2020comparing,
  title={Comparing different deep learning architectures for classification of chest radiographs},
  author={Bressem, Keno K and Adams, Lisa C and Erxleben, Christoph and Hamm, Bernd and Niehues, Stefan M and Vahldiek, Janis L},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--16},
  year={2020},
  publisher={Nature Publishing Group}
}


@article{shuja2021covid,
  title={COVID-19 open source data sets: a comprehensive survey},
  author={Shuja, Junaid and Alanazi, Eisa and Alasmary, Waleed and Alashaikh, Abdulaziz},
  journal={Applied Intelligence},
  volume={51},
  number={3},
  pages={1296--1325},
  year={2021},
  publisher={Springer}
}


@article{bassi2021deep,
  title={A deep convolutional neural network for COVID-19 detection using chest X-rays},
  author={Bassi, Pedro RAS and Attux, Romis},
  journal={Research on Biomedical Engineering},
  pages={1--10},
  year={2021},
  publisher={Springer},
  abstract={detects covid using transfere learning single and doble: imagenet -> chexnext->covid  and imagenet -> chexnext14->covid
usaes backbone resnet or chexnet.}
}

@article{shazia2021comparative,
    title={A Comparative Study of Multiple Neural Network for Detection of Covid 19 on Chest X-Ray},
    author={Shazia, Anis and Xuan, Tan Zi and Chuah, Joon Huang and Usman, Juliana and Qian, Pengjiang and Lai, Khin Wee},
    journal={EURASIP J. Adv. Signal Process.},
    number={50},
    year={2021}
}

@article{luo2020comparison,
  title={Comparison and benchmarking of ai models and frameworks on mobile devices},
  author={Luo, Chunjie and He, Xiwen and Zhan, Jianfeng and Wang, Lei and Gao, Wanling and Dai, Jiahui},
  journal={arXiv preprint arXiv:2005.05085},
  year={2020}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}


@article{matsuura2018tuberculous,
  title={Tuberculous pneumonia},
  author={Matsuura, Hiroki and Yamaji, Yasufumi},
  journal={QJM: An International Journal of Medicine},
  volume={111},
  number={2},
  pages={131--131},
  year={2018},
  publisher={Oxford University Press}
}

@article{liu2017survey,
  title={A survey of deep neural network architectures and their applications},
  author={Liu, Weibo and Wang, Zidong and Liu, Xiaohui and Zeng, Nianyin and Liu, Yurong and Alsaadi, Fuad E},
  journal={Neurocomputing},
  volume={234},
  pages={11--26},
  year={2017},
  publisher={Elsevier}
}


@inproceedings{stirenko2018chest,
  title={Chest X-ray analysis of tuberculosis by deep learning with segmentation and augmentation},
  author={Stirenko, Sergii and Kochura, Yuriy and Alienin, Oleg and Rokovyi, Oleksandr and Gordienko, Yuri and Gang, Peng and Zeng, Wei},
  booktitle={2018 IEEE 38th International Conference on Electronics and Nanotechnology (ELNANO)},
  pages={422--428},
  year={2018},
  organization={IEEE}
}

@article{greenspan2020position,
  title={Position paper on COVID-19 imaging and AI: From the clinical needs and technological challenges to initial AI solutions at the lab and national level towards a new era for AI in healthcare},
  author={Greenspan, Hayit and Est{\'e}par, Ra{\'u}l San Jos{\'e} and Niessen, Wiro J and Siegel, Eliot and Nielsen, Mads},
  journal={Medical image analysis},
  volume={66},
  pages={101800},
  year={2020},
  publisher={Elsevier}
}


@article{gupta2021instacovnet,
  title={InstaCovNet-19: A deep learning classification model for the detection of COVID-19 patients using Chest X-ray},
  author={Gupta, Anunay and Gupta, Shreyansh and Katarya, Rahul and others},
  journal={Applied Soft Computing},
  volume={99},
  pages={106859},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017},
  abstract={of a total of 13,975 CXR https://github.com/lindawangg/COVID-Net}
}

@article{wang2020covid,
  title={Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images},
  author={Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
  journal={Scientific Reports},
  volume={10},
  number={1},
  pages={1--12},
  year={2020},
  publisher={Nature Publishing Group}
}


@article{dey2021customized,
  title={Customized VGG19 architecture for pneumonia detection in chest X-rays},
  author={Dey, Nilanjan and Zhang, Yu-Dong and Rajinikanth, V and Pugalenthi, R and Raja, N Sri Madhava},
  journal={Pattern Recognition Letters},
  volume={143},
  pages={67--74},
  year={2021},
  publisher={Elsevier},
  abstract={DTL vgg16 binary covid vs no-covid. Also test VGG19, AlexNet, VGG16, VGG19 and ResNet50}
}

@article{chen2020two,
  title={Two-stream collaborative network for multi-label chest X-ray Image classification with lung segmentation},
  author={Chen, Bingzhi and Zhang, Zheng and Lin, Jianyong and Chen, Yi and Lu, Guangming},
  journal={Pattern Recognition Letters},
  volume={135},
  pages={221--227},
  year={2020},
  publisher={Elsevier},
  abstract={proposes TSCN to solve 14 labels for ChextNext-14, segment with Unet, then a two branche classifier.}
}

@article{guan202:CRAL,
  title={Multi-label chest X-ray image classification via category-wise residual attention learning},
  author={Guan, Qingji and Huang, Yaping},
  journal={Pattern Recognition Letters},
  volume={130},
  pages={259--266},
  year={2020},
  publisher={Elsevier}
}

@misc{rmsprop,
  author = {Goeffrey Hinton and Nish Srivastava and Kevin Swersky},
 title={Neural Networks for Machine Learning. Rmsprop: Divide the gradient by a running    average of its recent magnitude (Unpublished)},
 url={http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf},
 year={Consulted August 30, 2021}
}

@article{zhong2021deep,
  title={Deep metric learning-based image retrieval system for chest radiograph and its clinical applications in COVID-19},
  author={Zhong, Aoxiao and Li, Xiang and Wu, Dufan and Ren, Hui and Kim, Kyungsang and Kim, Younggon and Buch, Varun and Neumark, Nir and Bizzo, Bernardo and Tak, Won Young and others},
  journal={Medical Image Analysis},
  volume={70},
  pages={101993},
  year={2021},
  publisher={Elsevier}
}


@misc{chexnet_code,
 author = {Xinyu Weng, Nan Zhuang, Jingjing Tian and Yingcheng Liu},
 title={CheXNet for Classification and Localization of Thoracic Diseases (an alternative implementation); Consulted August 30},
 url={https://github.com/arnoweng/CheXNet},
 year={2021}
}


@inproceedings{shen2018dynamic,
  title={Dynamic routing on deep neural network for thoracic disease classification and sensitive area localization},
  author={Shen, Yan and Gao, Mingchen},
  booktitle={International Workshop on Machine Learning in Medical Imaging},
  pages={389--397},
  year={2018},
  organization={Springer}
}

@article{shoeibi2020automated,
  title={Automated detection and forecasting of covid-19 using deep learning techniques: A review},
  author={Shoeibi, Afshin and Khodatars, Marjane and Alizadehsani, Roohallah and Ghassemi, Navid and Jafari, Mahboobeh and Moridian, Parisa and Khadem, Ali and Sadeghi, Delaram and Hussain, Sadiq and Zare, Assef and others},
  journal={arXiv preprint arXiv:2007.10785},
  year={2020}
}


@inproceedings{davis2006relationship,
  title={The relationship between Precision-Recall and ROC curves},
  author={Davis, Jesse and Goadrich, Mark},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={233--240},
  year={2006}
}

@article{hanley1983method,
  title={A method of comparing the areas under receiver operating characteristic curves derived from the same cases.},
  author={Hanley, James A and McNeil, Barbara J},
  journal={Radiology},
  volume={148},
  number={3},
  pages={839--843},
  year={1983}
}

@article{saito2015precision,
  title={The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets},
  author={Saito, Takaya and Rehmsmeier, Marc},
  journal={PloS one},
  volume={10},
  number={3},
  pages={e0118432},
  year={2015},
  publisher={Public Library of Science}
}


@article{huang2020clinical,
  title={Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China},
  author={Huang, Chaolin and Wang, Yeming and Li, Xingwang and Ren, Lili and Zhao, Jianping and Hu, Yi and Zhang, Li and Fan, Guohui and Xu, Jiuyang and Gu, Xiaoying and others},
  journal={The Lancet},
  volume={395},
  number={10223},
  pages={497--506},
  year={2020},
  publisher={Elsevier}
}


@article{roberts2021common,
  title={Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans},
  author={Roberts, Michael and Driggs, Derek and Thorpe, Matthew and Gilbey, Julian and Yeung, Michael and Ursprung, Stephan and Aviles-Rivero, Angelica I and Etmann, Christian and McCague, Cathal and Beer, Lucian and others},
  journal={Nature Machine Intelligence},
  volume={3},
  number={3},
  pages={199--217},
  year={2021},
  publisher={Nature Publishing Group}
}


@article{ISMAEL2021114054,
title = {Deep learning approaches for COVID-19 detection based on chest X-ray images},
journal = {Expert Systems with Applications},
volume = {164},
pages = {114054},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114054},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420308198},
author = {Aras M. Ismael and Abdulkadir Şengür},
keywords = {COVID-19, Chest X-ray images, Deep learning, Convolutional neural networks, Local texture descriptors},
abstract = {COVID-19 is a novel virus that causes infection in both the upper respiratory tract and the lungs. The numbers of cases and deaths have increased on a daily basis on the scale of a global pandemic. Chest X-ray images have proven useful for monitoring various lung diseases and have recently been used to monitor the COVID-19 disease. In this paper, deep-learning-based approaches, namely deep feature extraction, fine-tuning of pretrained convolutional neural networks (CNN), and end-to-end training of a developed CNN model, have been used in order to classify COVID-19 and normal (healthy) chest X-ray images. For deep feature extraction, pretrained deep CNN models (ResNet18, ResNet50, ResNet101, VGG16, and VGG19) were used. For classification of the deep features, the Support Vector Machines (SVM) classifier was used with various kernel functions, namely Linear, Quadratic, Cubic, and Gaussian. The aforementioned pretrained deep CNN models were also used for the fine-tuning procedure. A new CNN model is proposed in this study with end-to-end training. A dataset containing 180 COVID-19 and 200 normal (healthy) chest X-ray images was used in the study’s experimentation. Classification accuracy was used as the performance measurement of the study. The experimental works reveal that deep learning shows potential in the detection of COVID-19 based on chest X-ray images. The deep features extracted from the ResNet50 model and SVM classifier with the Linear kernel function produced a 94.7% accuracy score, which was the highest among all the obtained results. The achievement of the fine-tuned ResNet50 model was found to be 92.6%, whilst end-to-end training of the developed CNN model produced a 91.6% result. Various local texture descriptors and SVM classifications were also used for performance comparison with alternative deep approaches; the results of which showed the deep approaches to be quite efficient when compared to the local texture descriptors in the detection of COVID-19 based on chest X-ray images.}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  publisher={IEEE}
}

@article{weiss2016survey,
  title={A survey of transfer learning},
  author={Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
  journal={Journal of Big data},
  volume={3},
  number={1},
  pages={1--40},
  year={2016},
  publisher={SpringerOpen}
}

@inproceedings{oquab2014learning,
  title={Learning and transferring mid-level image representations using convolutional neural networks},
  author={Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1717--1724},
  year={2014}
}

@article{lou2020serology,
  title={Serology characteristics of SARS-CoV-2 infection after exposure and post-symptom onset},
  author={Lou, Bin and Li, Ting-Dong and Zheng, Shu-Fa and Su, Ying-Ying and Li, Zhi-Yong and Liu, Wei and Yu, Fei and Ge, Sheng-Xiang and Zou, Qian-Da and Yuan, Quan and others},
  journal={European Respiratory Journal},
  volume={56},
  number={2},
  year={2020},
  publisher={Eur Respiratory Soc}
}

@misc{chest14_ray14_relabelled,
  author = {Ingo Lütkebohle},
  title = {{BWorld Robot Control Software}},
  howpublished = "\url{https://stanfordmedicine.app.box.com/s/b3gk9qnanzrdocqge0pbuh07mreu5x7y/folder/49785298071}",
  year = {2008},
  note = "[Online; accessed 19-July-2008]"
}

@article{o2021age,
  title={Age-specific mortality and immunity patterns of SARS-CoV-2},
  author={O’Driscoll, Megan and Dos Santos, Gabriel Ribeiro and Wang, Lin and Cummings, Derek AT and Azman, Andrew S and Paireau, Juliette and Fontanet, Arnaud and Cauchemez, Simon and Salje, Henrik},
  journal={Nature},
  volume={590},
  number={7844},
  pages={140--145},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{VABRET2020910,
title = {Immunology of COVID-19: Current State of the Science},
journal = {Immunity},
volume = {52},
number = {6},
pages = {910-941},
year = {2020},
doi = {https://doi.org/10.1016/j.immuni.2020.05.002},
author = {Nicolas Vabret and Graham J. Britton and Conor Gruber and Samarth Hegde and Joel Kim and Maria Kuksin and Rachel Levantovsky and Louise Malle and Alvaro Moreira and Matthew D. Park and Luisanna Pia and Emma Risson and Miriam Saffern and Bérengère Salomé and Myvizhi {Esai Selvan} and Matthew P. Spindler and Jessica Tan and Verena {van der Heide} and Jill K. Gregory and Konstantina Alexandropoulos and Nina Bhardwaj and Brian D. Brown and Benjamin Greenbaum and Zeynep H. Gümüş and Dirk Homann and Amir Horowitz and Alice O. Kamphorst and Maria A. {Curotto de Lafaille} and Saurabh Mehandru and Miriam Merad and Robert M. Samstein and Manasi Agrawal and Mark Aleynick and Meriem Belabed and Matthew Brown and Maria Casanova-Acebes and Jovani Catalan and Monica Centa and Andrew Charap and Andrew Chan and Steven T. Chen and Jonathan Chung and Cansu Cimen Bozkus and Evan Cody and Francesca Cossarini and Erica Dalla and Nicolas Fernandez and John Grout and Dan Fu Ruan and Pauline Hamon and Etienne Humblin and Divya Jha and Julia Kodysh and Andrew Leader and Matthew Lin and Katherine Lindblad and Daniel Lozano-Ojalvo and Gabrielle Lubitz and Assaf Magen and Zafar Mahmood and Gustavo Martinez-Delgado and Jaime Mateus-Tique and Elliot Meritt and Chang Moon and Justine Noel and Tim O’Donnell and Miyo Ota and Tamar Plitt and Venu Pothula and Jamie Redes and Ivan {Reyes Torres} and Mark Roberto and Alfonso R. Sanchez-Paulete and Joan Shang and Alessandra Soares Schanoski and Maria Suprun and Michelle Tran and Natalie Vaninov and C. Matthias Wilk and Julio Aguirre-Ghiso and Dusan Bogunovic and Judy Cho and Jeremiah Faith and Emilie Grasset and Peter Heeger and Ephraim Kenigsberg and Florian Krammer and Uri Laserson},
}

@article{deniz2018transfer,
  title={Transfer learning based histopathologic image classification for breast cancer detection},
  author={Deniz, Erkan and {\c{S}}eng{\"u}r, Abdulkadir and Kadiro{\u{g}}lu, Zehra and Guo, Yanhui and Bajaj, Varun and Budak, {\"U}mit},
  journal={Health information science and systems},
  volume={6},
  number={1},
  pages={1--7},
  year={2018},
  publisher={Springer}
}


@article{sufian2020survey,
  title={A survey on deep transfer learning to edge computing for mitigating the COVID-19 pandemic},
  author={Sufian, Abu and Ghosh, Anirudha and Sadiq, Ali Safaa and Smarandache, Florentin},
  journal={Journal of Systems Architecture},
  volume={108},
  pages={101830},
  year={2020},
  publisher={Elsevier}
}


@article{ai2020correlation,
  title={Correlation of chest CT and RT-PCR testing for coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases},
  author={Ai, Tao and Yang, Zhenlu and Hou, Hongyan and Zhan, Chenao and Chen, Chong and Lv, Wenzhi and Tao, Qian and Sun, Ziyong and Xia, Liming},
  journal={Radiology},
  volume={296},
  number={2},
  pages={E32--E40},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{agrawal2021focuscovid,
  title={FocusCovid: automated COVID-19 detection using deep learning with chest X-ray images},
  author={Agrawal, Tarun and Choudhary, Prakash},
  journal={Evolving Systems},
  pages={1--15},
  year={2021},
  publisher={Springer}
}

@misc{world2020director,
  title={WHO Director-General's opening remarks at the media briefing on COVID-19-11 March 2020},
  author={World Health Organization and others},
  year={2020},
  publisher={Geneva, Switzerland}
}

@article{wong2020frequency,
  title={Frequency and distribution of chest radiographic findings in patients positive for COVID-19},
  author={Wong, Ho Yuen Frank and Lam, Hiu Yin Sonia and Fong, Ambrose Ho-Tung and Leung, Siu Ting and Chin, Thomas Wing-Yan and Lo, Christine Shing Yen and Lui, Macy Mei-Sze and Lee, Jonan Chun Yin and Chiu, Keith Wan-Hang and Chung, Tom Wai-Hin and others},
  journal={Radiology},
  volume={296},
  number={2},
  pages={E72--E78},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{rajpurkar2018deep,
  title={Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists},
  author={Rajpurkar, Pranav and Irvin, Jeremy and Ball, Robyn L and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis P and others},
  journal={PLoS Medicine},
  volume={15},
  number={11},
  pages={e1002686},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{wang2017chestx,
  title={Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases},
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2097--2106},
  year={2017}
}

@article{litjens2017survey,
  title={A survey on deep learning in medical image analysis},
  author={Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and Van Der Laak, Jeroen Awm and Van Ginneken, Bram and S{\'a}nchez, Clara I},
  journal={Medical Image Analysis},
  volume={42},
  pages={60--88},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{tan2018survey,
  title={A survey on deep transfer learning},
  author={Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
  booktitle={International Conference on Artificial Neural Networks},
  pages={270--279},
  year={2018},
  organization={Springer}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {ImageNet Large Scale Visual Recognition Challenge},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{baltruschat2019comparison,
  title={Comparison of deep learning approaches for multi-label chest X-ray classification},
  author={Baltruschat, Ivo M and Nickisch, Hannes and Grass, Michael and Knopp, Tobias and Saalbach, Axel},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--10},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{puttagunta2021detection,
  title={Detection of Tuberculosis based on Deep Learning based methods},
  author={Puttagunta, Murali Krishna and Ravi, S},
  booktitle={Journal of Physics: Conference Series},
  volume={1767},
  number={1},
  pages={012004},
  year={2021},
  organization={IOP Publishing}
}

@inproceedings{liu2020rethinking,
  title={Rethinking computer-aided tuberculosis diagnosis},
  author={Liu, Yun and Wu, Yu-Huan and Ban, Yunfeng and Wang, Huifang and Cheng, Ming-Ming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2646--2655},
  year={2020}
}

@article{chauhan2014role,
  title={Role of gist and PHOG features in computer-aided diagnosis of tuberculosis without segmentation},
  author={Chauhan, Arun and Chauhan, Devesh and Rout, Chittaranjan},
  journal={PloS one},
  volume={9},
  number={11},
  pages={e112980},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

@article{jaeger2014two,
  title={Two public chest X-ray datasets for computer-aided screening of pulmonary diseases},
  author={Jaeger, Stefan and Candemir, Sema and Antani, Sameer and W{\'a}ng, Y{\`\i}-Xi{\'a}ng J and Lu, Pu-Xuan and Thoma, George},
  journal={Quantitative imaging in medicine and surgery},
  volume={4},
  number={6},
  pages={475},
  year={2014},
  publisher={AME Publications}
}


@article{shiraishi2000development,
  title={Development of a digital image database for chest radiographs with and without a lung nodule: receiver operating characteristic analysis of radiologists' detection of pulmonary nodules},
  author={Shiraishi, Junji and Katsuragawa, Shigehiko and Ikezoe, Junpei and Matsumoto, Tsuneo and Kobayashi, Takeshi and Komatsu, Ken-ichi and Matsui, Mitate and Fujita, Hiroshi and Kodera, Yoshie and Doi, Kunio},
  journal={American Journal of Roentgenology},
  volume={174},
  number={1},
  pages={71--74},
  year={2000},
  publisher={Am Roentgen Ray Soc}
}

@ARTICLE{Fortunato2010,
  author  = {Fortunato, S.},
  title   = {Community detection in graphs},
  journal = {Phys. Rep.-Rev. Sec. Phys. Lett.},
  volume  = {486},
  year    = {2010},
  pages   = {75-174}
}

@ARTICLE{NewmanGirvan2004,
  author  = {Newman, M. E. J. and Girvan, M.},
  title   = {Finding and evaluating community structure in networks},
  journal = {Phys. Rev. E.},
  volume  = {69},
  year    = {2004},
  pages   = {026113}
}

@ARTICLE{Vehlowetal2013,
  author  = {Vehlow, C. and Reinhardt, T. and Weiskopf, D.},
  title   = {Visualizing Fuzzy Overlapping Communities in Networks},
  journal = {IEEE Trans. Vis. Comput. Graph.},
  volume  = {19},
  year    = {2013},
  pages   = {2486-2495}
}

@ARTICLE{Raghavanetal2007,
  author  = {Raghavan, U. and Albert, R. and Kumara, S.},
  title   = {Near linear time algorithm to detect community structures in large-scale networks},
  journal = {Phys. Rev E.},
  volume  = {76},
  year    = {2007},
  pages   = {036106}
}

@ARTICLE{SubeljBajec2011a,
  author  = {\v{S}ubelj, L. and Bajec, M.},
  title   = {Robust network community detection using balanced propagation},
  journal = {Eur. Phys. J. B.},
  volume  = {81},
  year    = {2011},
  pages   = {353-362}
}

@ARTICLE{Louetal2013,
  author  = {Lou, H. and Li, S. and Zhao, Y.},
  title   = {Detecting community structure using label propagation with weighted coherent neighborhood propinquity},
  journal = {Physica A.},
  volume  = {392},
  year    = {2013},
  pages   = {3095-3105}
}

@ARTICLE{Clausetetal2004,
  author  = {Clauset, A. and Newman, M. E. J. and Moore, C.},
  title   = {Finding community structure in very large networks},
  journal = {Phys. Rev. E.},
  volume  = {70},
  year    = {2004},
  pages   = {066111}
}

@ARTICLE{Blondeletal2008,
  author  = {Blondel, V. D. and Guillaume, J. L. and Lambiotte, R. and Lefebvre, E.},
  title   = {Fast unfolding of communities in large networks},
  journal = {J. Stat. Mech.-Theory Exp.},
  volume  = {2008},
  year    = {2008},
  pages   = {P10008}
}

@ARTICLE{SobolevskyCampari2014,
  author  = {Sobolevsky, S. and Campari, R.},
  title   = {General optimization technique for high-quality community detection in complex networks},
  journal = {Phys. Rev. E.},
  volume  = {90},
  year    = {2014},
  pages   = {012811}
}

@ARTICLE{FortunatoBarthelemy2007,
  author  = {Fortunato, S. and Barthelemy, M.},
  title   = {Resolution limit in community detection},
  journal = {Proc. Natl. Acad. Sci. U. S. A.},
  volume  = {104},
  year    = {2007},
  pages   = {36-41}
}

@ARTICLE{SubeljBajec2011b,
  author  = {\v{S}ubelj, L. and Bajec, M.},
  title   = {Unfolding communities in large complex networks: Combining defensive and offensive label propagation for core extraction},
  journal = {Phys. Rev. E.},
  volume  = {83},
  year    = {2011},
  pages   = {036103}
}

@ARTICLE{WangLi2013,
  author  = {Wang, X. and Li, J.},
  title   = {Detecting communities by the core-vertex and intimate degree in complex networks},
  journal = {Physica A.},
  volume  = {392},
  year    = {2013},
  pages   = {2555-2563}
}

@ARTICLE{Lietal2013,
  author  = {Li, J. and Wang, X. and Eustace, J.},
  title   = {Detecting overlapping communities by seed community in weighted complex networks},
  journal = {Physica A.},
  volume  = {392},
  year    = {2013},
  pages   = {6125-6134}
}

@ARTICLE{Fabioetal2013,
  author  = {Fabio, D. R. and Fabio, D. and Carlo, P.},
  title   = {Profiling core-periphery network structure by random walkers},
  journal = {Sci. Rep.},
  volume  = {3},
  year    = {2013},
  pages   = {1467}
}

@ARTICLE{Chenetal2013,
  author  = {Chen, Q. and Wu, T. T. and Fang, M.},
  title   = {Detecting local community structure in complex networks based on local degree central nodes},
  journal = {Physica A.},
  volume  = {392},
  year    = {2013},
  pages   = {529-537}
}

@ARTICLE{Zhangetal2007,
  author  = {Zhang, S. and Wang, R. and Zhang, X.},
  title   = {Identification of overlapping community structure in complex networks using fuzzy c-means clustering},
  journal = {Physica A.},
  volume  = {374},
  year    = {2007},
  pages   = {483-490}
}

@ARTICLE{Nepuszetal2008,
  author  = {Nepusz, T. and Petr\'oczi, A. and N\'egyessy, L. and Bazs\'o, F.},
  title   = {Fuzzy communities and the concept of bridgeness in complex networks},
  journal = {Phys. Rev. E.},
  volume  = {77},
  year    = {2008},
  pages   = {016107}
}

@ARTICLE{FabricioLiang2013,
  author  = {Fabricio, B. and Liang, Z.},
  title   = {Fuzzy community structure detection by particle competition and cooperation},
  journal = {Soft Comput.},
  volume  = {17},
  year    = {2013},
  pages   = {659-673}
}

@ARTICLE{Sunetal2011,
  author  = {Sun, P. and Gao, L. and Han, S.},
  title   = {Identification of overlapping and non-overlapping community structure by fuzzy clustering in complex networks},
  journal = {Inf. Sci.},
  volume  = {181},
  year    = {2011},
  pages   = {1060-1071}
}

@ARTICLE{Wangetal2013,
  author  = {Wang, W. and Liu, D. and Liu, X. and Pan, L.},
  title   = {Fuzzy overlapping community detection based on local random walk and multidimensional scaling},
  journal = {Physica A.},
  volume  = {392},
  year    = {2013},
  pages   = {6578-6586}
}

@ARTICLE{Psorakisetal2011,
  author  = {Psorakis, I. and Roberts, S. and Ebden, M. and Sheldon, B.},
  title   = {Overlapping community detection using Bayesian non-negative matrix factorization},
  journal = {Phys. Rev. E.},
  volume  = {83},
  year    = {2011},
  pages   = {066114}
}

@CONFERENCE{ZhangYeung2012,
  author  = {Zhang, Y. and Yeung, D.},
  title   = {Overlapping Community Detection via Bounded Nonnegative Matrix Tri-Factorization},
  booktitle = {In Proc. ACM SIGKDD Conf.},
  year    = {2012},
  pages   = {606-614}
}

@ARTICLE{Liu2010,
  author  = {Liu, J.},
  title   = {Fuzzy modularity and fuzzy community structure in networks},
  journal = {Eur. Phys. J. B.},
  volume  = {77},
  year    = {2010},
  pages   = {547-557}
}

@ARTICLE{Havensetal2013,
  author  = {Havens, T. C. and Bezdek, J. C. and Leckie, C., Ramamohanarao, K. and Palaniswami, M.},
  title   = {A Soft Modularity Function For Detecting Fuzzy Communities in Social Networks},
  journal = {IEEE Trans. Fuzzy Syst.},
  volume  = {21},
  year    = {2013},
  pages   = {1170-1175}
}

@misc{Newman2013,
  author = {Newman, M. E. J.},
  title  = {Network data},
  howpublished = "\url{http://www-personal.umich.edu/~mejn/netdata/}",
  year = {2013}
}

@ARTICLE{SubeljBajec2012,
  author  = {\v{S}ubelj, L. and Bajec, M.},
  title   = {Ubiquitousness of link-density and link-pattern communities in real-world networks},
  journal = {Eur. Phys. J. B.},
  volume  = {85},
  year    = {2012},
  pages   = {1-11}
}

@ARTICLE{Lancichinettietal2008,
  author  = {Lancichinetti, A. and Fortunato, S. and Radicchi, F.},
  title   = {Benchmark graphs for testing community detection algorithms},
  journal = {Phys. Rev. E.},
  volume  = {78},
  year    = {2008},
  pages   = {046110}
}

@ARTICLE{Liuetal2014,
  author  = {Liu, W. and Pellegrini, M. and Wang, X.},
  title   = {Detecting Communities Based on Network Topology},
  journal = {Sci. Rep.},
  volume  = {4},
  year    = {2014},
  pages   = {5739}
}

@ARTICLE{Danonetal2005,
  author  = {Danon, L. and Diaz-Guilera, A. and Duch, J. and Arenas, A.},
  title   = {Comparing community structure identification},
  journal = {J. Stat. Mech.-Theory Exp.},
  volume  = {},
  year    = {2005},
  pages   = {P09008}
}

@ARTICLE{Gregory2011,
  author  = {Gregory, S.},
  title   = {Fuzzy overlapping communities in networks},
  journal = {J. Stat. Mech.-Theory Exp.},
  volume  = {},
  year    = {2011},
  pages   = {P02017}
}

@ARTICLE{LancichinettiFortunato2009,
  author  = {Lancichinetti, A. and Fortunato, S.},
  title   = {Benchmarks for testing community detection algorithms on directed and weighted graphs with overlapping communities},
  journal = {Phys. Rev. E.},
  volume  = {80},
  year    = {2009},
  pages   = {016118}
}

@CONFERENCE{HullermeierRifqi2009,
  author  = {Hullermeier, E. and Rifqi, M.},
  title   = {A Fuzzy Variant of the Rand Index for Comparing Clustering Structures},
  booktitle = {in Proc. IFSA/EUSFLAT Conf.},
  year    = {2009},
  pages   = {1294-1298}
}

@article{pub.1136450856,
 author = {Schuler, Charles F. and Gherasim, Carmen and O’Shea, Kelly and Manthei, David M. and Chen, Jesse and Giacherio, Don and Troost, Jonathan P. and Baldwin, James L. and Baker, James R.},
 doi = {10.1371/journal.pone.0248729},
 journal = {PLOS ONE},
 keywords = {},
 number = {3},
 pages = {e0248729},
 title = {Accurate point-of-care serology tests for COVID-19},
 url = {https://app.dimensions.ai/details/publication/pub.1136450856 and https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0248729&type=printable},
 volume = {16},
 year = {2021}
}

@article{LIU2021112817,
title = {Nanozyme chemiluminescence paper test for rapid and sensitive detection of SARS-CoV-2 antigen},
journal = {Biosensors and Bioelectronics},
volume = {173},
pages = {112817},
year = {2021},
issn = {0956-5663},
doi = {https://doi.org/10.1016/j.bios.2020.112817},
url = {https://www.sciencedirect.com/science/article/pii/S0956566320308034},
author = {Dan Liu and Chenhui Ju and Chao Han and Rui Shi and Xuehui Chen and Demin Duan and Jinghua Yan and Xiyun Yan},
keywords = {SARS-CoV-2, Antigen detection, Paper test, Nanozyme, Chemiluminescence},
abstract = {COVID-19 has evolved into a global pandemic. Early and rapid detection is crucial to control of the SARS-CoV-2 transmission. While representing the gold standard for early diagnosis, nucleic acid tests for SARS-CoV-2 are often complicated and time-consuming. Serological rapid antibody tests are characterized by high rates of false-negative diagnoses, especially during early infection. Here, we developed a novel nanozyme-based chemiluminescence paper assay for rapid and sensitive detection of SARS-CoV-2 spike antigen, which integrates nanozyme and enzymatic chemiluminescence immunoassay with the lateral flow strip. The core of our paper test is a robust Co–Fe@hemin-peroxidase nanozyme that catalyzes chemiluminescence comparable with natural peroxidase HRP and thus amplifies immune reaction signal. The detection limit for recombinant spike antigen of SARS-CoV-2 was 0.1 ng/mL, with a linear range of 0.2-100 ng/mL. Moreover, the sensitivity of test for pseudovirus could reach 360 TCID50/mL, which was comparable with ELISA method. The strip recognized SARS-CoV-2 antigen specifically, and there was no cross reaction with other coronaviruses or influenza A subtypes. This testing can be completed within 16 min, much shorter compared to the usual 1-2 h required for currently used nucleic acid tests. Furthermore, signal detection is feasible using the camera of a standard smartphone. Ingredients for nanozyme synthesis are simple and readily available, considerably lowering the overall cost. In conclusion, our paper test provides a high-sensitive point-of-care testing (POCT) approach for SARS-CoV-2 antigen detection, which should greatly facilitate early screening of SARS-CoV-2 infections, and considerably lower the financial burden on national healthcare resources.}
}

@Article{Gupta2021,
  author={Gupta, Niharika
  and Augustine, Shine
  and Narayan, Tarun
  and O'Riordan, Alan
  and Das, Asmita
  and Kumar, D.
  and Luong, John H. T.
  and Malhotra, Bansi D.},
  title={Point-of-Care PCR Assays for COVID-19 Detection},
  journal={Biosensors},
  year={2021},
  month={May},
  day={01},
  publisher={MDPI},
  volume={11},
  number={5},
  pages={141},
  keywords={COVID-19; digital PCR; electrochemical; point-of-care; polymerase chain reaction; Animals; COVID-19/*diagnosis; COVID-19 Nucleic Acid Testing/*instrumentation/methods; CRISPR-Cas Systems; Equipment Design; Humans; *Point-of-Care Testing; Polymerase Chain Reaction/*instrumentation/methods; SARS-CoV-2/genetics/*isolation {\&} purification},
  abstract={Molecular diagnostics has been the front runner in the world's response to the COVID-19 pandemic. Particularly, reverse transcriptase-polymerase chain reaction (RT-PCR) and the quantitative variant (qRT-PCR) have been the gold standard for COVID-19 diagnosis. However, faster antigen tests and other point-of-care (POC) devices have also played a significant role in containing the spread of SARS-CoV-2 by facilitating mass screening and delivering results in less time. Thus, despite the higher sensitivity and specificity of the RT-PCR assays, the impact of POC tests cannot be ignored. As a consequence, there has been an increased interest in the development of miniaturized, high-throughput, and automated PCR systems, many of which can be used at point-of-care. This review summarizes the recent advances in the development of miniaturized PCR systems with an emphasis on COVID-19 detection. The distinct features of digital PCR and electrochemical PCR are detailed along with the challenges. The potential of CRISPR/Cas technology for POC diagnostics is also highlighted. Commercial RT-PCR POC systems approved by various agencies for COVID-19 detection are discussed.},
  note={34062874[pmid]},
  note={PMC8147281[pmcid]},
  note={bios11050141[PII]},
  issn={2079-6374},
  doi={10.3390/bios11050141},
  url={https://pubmed.ncbi.nlm.nih.gov/34062874},
  url={https://doi.org/10.3390/bios11050141},
  language={eng}
}

@Article{Apra2021,
  author={Apra, Caroline
  and Caucheteux, Charlotte
  and Mensch, Arthur
  and Mansour, Jenny
  and Bernaux, M{\'e}lodie
  and Dechartres, Agn{\`e}s
  and Debuc, Erwan
  and Lescure, Xavier
  and Dinh, Aur{\'e}lien
  and Yordanov, Youri
  and Jourdain, Patrick
  and Paris, Nicolas
  and Gramfort, Alexandre
  and Aime-Eusebi, Am{\'e}lie
  and Bleibtreu, Alexandre
  and Deconinck, Laur{\`e}ne
  and Katlama, Christine
  and Lebel, Josselin
  and Lescure, Fran{\c{c}}ois-Xavier
  and Artigou, Yves
  and Banzet, Am{\'e}lie
  and Boucheron, Elodie
  and Boudier, Christiane
  and Buzenac, Edouard
  and Chapron, Marie-Claire
  and Chekaoui, Dalhia
  and De Bastard, Laurent
  and Grenier, Alexandre
  and Haas, Pierre-Etienne
  and Hody, Julien
  and Jarraya, Mich{\`e}le
  and Lacaille, Louis
  and Le Guern, Aur{\'e}lie
  and Leclert, Jeremy
  and Male, Fanny
  and Marchand-Arvier, Jer{\^o}me
  and Martin-Blondet, Emmanuel
  and Nassour, Apolinne
  and Ourahou, Oussama
  and Penn, Thomas
  and Ribardiere, Ambre
  and Robin, Nicolas
  and Rouge, Camille
  and Schmidt, Nicolas
  and Villie, Pascaline
  and Collaboration, The AP-HP/Universities/Inserm COVID-19 Research
  and Committee, Writing
  and Committee, Data Science
  and Committee, Scientific
  and Committee, Covidom Regional Center Steering},
  title={Predictive usefulness of RT-PCR testing in different patterns of Covid-19 symptomatology: analysis of a French cohort of 12,810 outpatients},
  journal={Scientific Reports},
  year={2021},
  month={Oct},
  day={27},
  volume={11},
  number={1},
  pages={21233},
  abstract={Reverse transcriptase polymerase chain reaction (RT-PCR) is a key tool to diagnose Covid-19. Yet it may not be the most efficient test in all patients. In this paper, we develop a clinical strategy for prescribing RT-PCR to patients based on data from COVIDOM, a French cohort of 54,000 patients with clinically suspected Covid-19, including 12,810 patients tested by RT-PCR. We use a machine-learning algorithm (decision tree) in order to predict RT-PCR results based on the clinical presentation. We show that symptoms alone are sufficient to predict RT-PCR outcome with a mean average precision of 86{\%}. We identify combinations of symptoms that are predictive of RT-PCR positivity (90{\%} for anosmia/ageusia) or negativity (only 30{\%} of RT-PCR+{\thinspace}for a subgroup with cardiopulmonary symptoms): in both cases, RT-PCR provides little added diagnostic value. We propose a prescribing strategy based on clinical presentation that can improve the global efficiency of RT-PCR testing.},
  issn={2045-2322},
  doi={10.1038/s41598-021-99991-6},
  url={https://doi.org/10.1038/s41598-021-99991-6}
}


@article{vgg16,
  author = {Simonyan, Karen and Zisserman, Andrew},
  year = {2014},
  month = {09},
  pages = {},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal = {arXiv 1409.1556}
}

@article{DBLP:journals/corr/HuangLW16a,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.06993},
  eprinttype = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Mon, 10 Sep 2018 15:49:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HuangLW16a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8099852,
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},
  year={2017},
  volume={},
  number={},
  pages={3462-3471},
  doi={10.1109/CVPR.2017.369}
}

@Article{Wang2020,
  author={Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
  title={COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images},
  journal={Scientific Reports},
  year={2020},
  month={Nov},
  day={11},
  volume={10},
  number={1},
  pages={19549},
  abstract={The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.},
  issn={2045-2322},
  doi={10.1038/s41598-020-76550-z},
  url={https://doi.org/10.1038/s41598-020-76550-z}
}

@misc{cohen2020covid19,
  title={COVID-19 Image Data Collection},
  author={Joseph Paul Cohen and Paul Morrison and Lan Dao},
  year={2020},
  eprint={2003.11597},
  archivePrefix={arXiv},
  primaryClass={eess.IV}
}

@misc{figure1_2020covid19,
  title={Figure 1 COVID-19 chest x-ray data initiative},
  author={Linda Wang and Alexander Wong and Zhong Qiu Lin and Paul McInnis and Audrey Chung and Hayden Gunraj and James Lee and Matt Ross and Blake VanBerlo and Ashkan Ebadi and Kim-Ann Git and Abdul Al-Haimi},
  year={2020},
  url={https://github.com/agchung/Figure1-COVID-chestxray-dataset}
}

@misc{actualmed_2020covid19,
  title={Actualmed COVID-19 chest x-ray data initiative},
  author={Linda Wang and Alexander Wong and Zhong Qiu Lin and Paul McInnis and Audrey Chung and Hayden Gunraj and James Lee and Matt Ross and Blake VanBerlo and Ashkan Ebadi and Kim-Ann Git and Abdul Al-Haimi},
  year={2020},
  url={https://github.com/agchung/Actualmed-COVID-chestxray-dataset}
}

@misc{rsna_det_challlenge,
  title={RSNA pneumonia detection challenge.},
  author={Radiological Society of North America},
  year={2019},
  url={https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data}
}

@misc{rsna_det_challenge2,
  title={COVID-19 radiography database},
  author={Radiological Society of North America},
  year={2019},
  url={https://www.kaggle.com/tawsifurrahman/covid19-radiography-database}
}

@misc{siim_det_challenge,
  title={SIIM-FISABIO-RSNA COVID-19 Detection},
  author={SIIM and FISABIO and BIMCV and RSNA},
  year={2021},
  url={https://www.kaggle.com/tawsifurrahman/covid19-radiography-database}
}

@Article{00005382-202011000-00004,
  author={Litmanovich, Diana E.
  and Chung, Michael
  and Kirkbride, Rachael R.
  and Kicska, Gregory
  and Kanne, Jeffrey P.},
  title={Review of Chest Radiograph Findings of COVID-19 Pneumonia and Suggested Reporting Language},
  journal={Journal of Thoracic Imaging},
  year={2020},
  volume={35},
  number={6},
  keywords={coronavirus disease 2019; chest radiograph; standardized reporting language; severity assessment; pneumonia},
  abstract={The diagnosis of coronavirus disease 2019 (COVID-19) is confirmed by reverse transcription polymerase chain reaction. The utility of chest radiography (CXR) remains an evolving topic of discussion. Current reports of CXR findings related to COVID-19 contain varied terminology as well as various assessments of its sensitivity and specificity. This can lead to a misunderstanding of CXR reports and makes comparison between examinations and research studies challenging. With this need for consistency, we propose language for standardized CXR reporting and severity assessment of persons under investigation for having COVID-19, patients with a confirmed diagnosis of COVID-19, and patients who may have radiographic findings typical or suggestive of COVID-19 when the diagnosis is not suspected clinically. We recommend contacting the referring providers to discuss the likelihood of viral infection when typical or indeterminate features of COVID-19 pneumonia on CXR are present as an incidental finding. In addition, we summarize the currently available literature related to the use of CXR for COVID-19 and discuss the evolving techniques of obtaining CXR in COVID-19-positive patients. The recently published expert consensus statement on reporting chest computed tomography findings related to COVID-19, endorsed by the Radiological Society of North American (RSNA), the Society of Thoracic Radiology (STR), and American College of Radiology (ACR), serves as the framework for our proposal.},
  issn={0883-5993},
  url={https://journals.lww.com/thoracicimaging/Fulltext/2020/11000/Review_of_Chest_Radiograph_Findings_of_COVID_19.4.aspx}
}

@INPROCEEDINGS{9156613,
  author={Liu, Yun and Wu, Yu-Huan and Ban, Yunfeng and Wang, Huifang and Cheng, Ming-Ming},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Rethinking Computer-Aided Tuberculosis Diagnosis},
  year={2020},
  volume={},
  number={},
  pages={2643-2652},
  doi={10.1109/CVPR42600.2020.00272}
}

@ARTICLE{Hanley1983-tu,
  title    = "A method of comparing the areas under receiver operating
              characteristic curves derived from the same cases",
  author   = "Hanley, J A and McNeil, B J",
  abstract = "Receiver operating characteristic (ROC) curves are used to
              describe and compare the performance of diagnostic technology and
              diagnostic algorithms. This paper refines the statistical
              comparison of the areas under two ROC curves derived from the
              same set of patients by taking into account the correlation
              between the areas that is induced by the paired nature of the
              data. The correspondence between the area under an ROC curve and
              the Wilcoxon statistic is used and underlying Gaussian
              distributions (binormal) are assumed to provide a table that
              converts the observed correlations in paired ratings of images
              into a correlation between the two ROC areas. This between-area
              correlation can be used to reduce the standard error
              (uncertainty) about the observed difference in areas. This
              correction for pairing, analogous to that used in the paired
              t-test, can produce a considerable increase in the statistical
              sensitivity (power) of the comparison. For studies involving
              multiple readers, this method provides a measure of a component
              of the sampling variation that is otherwise difficult to obtain.",
  journal  = "Radiology",
  volume   =  148,
  number   =  3,
  pages    = "839--843",
  month    =  sep,
  year     =  1983,
  address  = "United States",
  language = "en"
}

@inproceedings{10.1145/1143844.1143874,
  author = {Davis, Jesse and Goadrich, Mark},
  title = {The Relationship between Precision-Recall and ROC Curves},
  year = {2006},
  isbn = {1595933832},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1143844.1143874},
  doi = {10.1145/1143844.1143874},
  abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
  booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
  pages = {233–240},
  numpages = {8},
  location = {Pittsburgh, Pennsylvania, USA},
  series = {ICML '06}
}

@ARTICLE{Saito2015-db,
  title    = "The precision-recall plot is more informative than the {ROC} plot
              when evaluating binary classifiers on imbalanced datasets",
  author   = "Saito, Takaya and Rehmsmeier, Marc",
  abstract = "Binary classifiers are routinely evaluated with performance
              measures such as sensitivity and specificity, and performance is
              frequently illustrated with Receiver Operating Characteristics
              (ROC) plots. Alternative measures such as positive predictive
              value (PPV) and the associated Precision/Recall (PRC) plots are
              used less frequently. Many bioinformatics studies develop and
              evaluate classifiers that are to be applied to strongly
              imbalanced datasets in which the number of negatives outweighs
              the number of positives significantly. While ROC plots are
              visually appealing and provide an overview of a classifier's
              performance across a wide range of specificities, one can ask
              whether ROC plots could be misleading when applied in imbalanced
              classification scenarios. We show here that the visual
              interpretability of ROC plots in the context of imbalanced
              datasets can be deceptive with respect to conclusions about the
              reliability of classification performance, owing to an intuitive
              but wrong interpretation of specificity. PRC plots, on the other
              hand, can provide the viewer with an accurate prediction of
              future classification performance due to the fact that they
              evaluate the fraction of true positives among positive
              predictions. Our findings have potential implications for the
              interpretation of a large number of studies that use ROC plots on
              imbalanced datasets.",
  journal  = "PLoS One",
  volume   =  10,
  number   =  3,
  pages    = "e0118432",
  month    =  mar,
  year     =  2015,
  language = "en"
}

@article{DBLP:journals/corr/abs-1808-05744,
  author    = {Yan Shen and
               Mingchen Gao},
  title     = {Dynamic Routing on Deep Neural Network for Thoracic Disease Classification
               and Sensitive Area Localization},
  journal   = {CoRR},
  volume    = {abs/1808.05744},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.05744},
  eprinttype = {arXiv},
  eprint    = {1808.05744},
  timestamp = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-05744.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GUAN2020259,
  title = {Multi-label chest X-ray image classification via category-wise residual attention learning},
  journal = {Pattern Recognition Letters},
  volume = {130},
  pages = {259-266},
  year = {2020},
  note = {Image/Video Understanding and Analysis (IUVA)},
  issn = {0167-8655},
  doi = {https://doi.org/10.1016/j.patrec.2018.10.027},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865518308559},
  author = {Qingji Guan and Yaping Huang},
  keywords = {Chest X-ray, Residual attention, Convolutional neural network, Image classification},
  abstract = {This paper considers the problem of multi-label thorax disease classification on chest X-ray images. Identifying one or more pathologies from a chest X-ray image is often hindered by the pathologies unrelated to the targets. In this paper, we address the above problem by proposing a category-wise residual attention learning (CRAL) framework. CRAL predicts the presence of multiple pathologies in a class-specific attentive view. It aims to suppress the obstacles of irrelevant classes by endowing small weights to the corresponding feature representation. Meanwhile, the relevant features would be strengthened by assigning larger weights. Specifically, the proposed framework consists of two modules: feature embedding module and attention learning module. The feature embedding module learns high-level features with a convolutional neural network (CNN) while the attention learning module focuses on exploring the assignment scheme of different categories. The attention module can be flexibly integrated into any feature embedding networks with end-to-end training. The comprehensive experiments are conducted on the Chest X-ray14 dataset. CRAL yields the average AUC score of 0.816 which is a new state of the art.}
}

@article{CHEN2020221,
  title = {Two-stream collaborative network for multi-label chest X-ray Image classification with lung segmentation},
  journal = {Pattern Recognition Letters},
  volume = {135},
  pages = {221-227},
  year = {2020},
  issn = {0167-8655},
  doi = {https://doi.org/10.1016/j.patrec.2020.04.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865520301380},
  author = {Bingzhi Chen and Zheng Zhang and Jianyong Lin and Yi Chen and Guangming Lu},
  keywords = {Two-stream collaborative network, Lung segmentation, Self-adaptive weighted fusion, Multi-label CXR image classification},
  abstract = {Automated chest X-ray (CXR) image analysis is often subject to serious disruption and misguided by its imaging artifacts and noise regions. To minimize such negative effects, many state-of-the-art works have made great efforts in the precise segmentation of lung fields. Based on these works, some image-based features can be extracted directly from lung filed to provide clues for many types of lung diseases such as lung nodule, cardiomegaly, pneumothorax, or emphysema. In this paper, we propose a novel two-stream collaborative network call TSCN for multi-label CXR image classification based on lung segmentation. Specifically, we first train a robust lung segmentor with U-Net and apply it to capture the lung filed from the original CXR image. Then we perform a two-stream feature fusion operation to aggregate the contextual information in both the global image and lung field for complementary feature learning. By taking advantage of the two-stream deep structures and two types of image inputs, a novel self-adaptive weighted fusion scheme is designed to jointly learn these two feature streams in the end-to-end training phase, in order to realize adaptive two-stream feature subsets selection and optimization. Extensive experiments on the ChestX-ray14 dataset demonstrate the effectiveness of the proposed method as compared with the state-of-the-art baselines.}
}

@Article{Baltruschat2019,
  author={Baltruschat, Ivo M.
  and Nickisch, Hannes
  and Grass, Michael
  and Knopp, Tobias
  and Saalbach, Axel},
  title={Comparison of Deep Learning Approaches for Multi-Label Chest X-Ray Classification},
  journal={Scientific Reports},
  year={2019},
  month={Apr},
  day={23},
  volume={9},
  number={1},
  pages={6381},
  abstract={The increased availability of labeled X-ray image archives (e.g. ChestX-ray14 dataset) has triggered a growing interest in deep learning techniques. To provide better insight into the different approaches, and their applications to chest X-ray classification, we investigate a powerful network architecture in detail: the ResNet-50. Building on prior work in this domain, we consider transfer learning with and without fine-tuning as well as the training of a dedicated X-ray network from scratch. To leverage the high spatial resolution of X-ray data, we also include an extended ResNet-50 architecture, and a network integrating non-image data (patient age, gender and acquisition type) in the classification process. In a concluding experiment, we also investigate multiple ResNet depths (i.e. ResNet-38 and ResNet-101). In a systematic evaluation, using 5-fold re-sampling and a multi-label loss function, we compare the performance of the different approaches for pathology classification by ROC statistics and analyze differences between the classifiers using rank correlation. Overall, we observe a considerable spread in the achieved performance and conclude that the X-ray-specific ResNet-38, integrating non-image data yields the best overall results. Furthermore, class activation maps are used to understand the classification process, and a detailed analysis of the impact of non-image features is provided.},
  issn={2045-2322},
  doi={10.1038/s41598-019-42294-8},
  url={https://doi.org/10.1038/s41598-019-42294-8}
}
